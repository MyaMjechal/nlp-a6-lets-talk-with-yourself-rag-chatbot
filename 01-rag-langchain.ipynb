{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLPK4WvHd1cr"
      },
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "# Retrieval-Augmented generation (RAG)\n",
        "\n",
        "RAG is a technique for augmenting LLM knowledge with additional, often private or real-time, data.\n",
        "\n",
        "LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model’s cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
        "\n",
        "<img src=\"https://github.com/MyaMjechal/nlp-a6-lets-talk-with-yourself-rag-chatbot/blob/main/images/RAG-process.png?raw=1\" >\n",
        "\n",
        "Introducing `ChakyBot`, an innovative chatbot designed to assist Chaky (the instructor) and TA (Gun) in explaining the lesson of the NLP course to students. Leveraging LangChain technology, ChakyBot excels in retrieving information from documents, ensuring a seamless and efficient learning experience for students engaging with the NLP curriculum.\n",
        "\n",
        "1. Prompt\n",
        "2. Retrieval\n",
        "3. Memory\n",
        "4. Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn_UVz0Vd1ct"
      },
      "outputs": [],
      "source": [
        "# #langchain library\n",
        "# !pip install langchain==0.0.350\n",
        "# #LLM\n",
        "# !pip install accelerate==0.25.0\n",
        "# !pip install transformers==4.36.2\n",
        "# !pip install bitsandbytes==0.41.2\n",
        "# #Text Embedding\n",
        "# !pip install sentence-transformers==2.2.2\n",
        "# !pip install InstructorEmbedding==1.0.1\n",
        "# #vectorstore\n",
        "# !pip install pymupdf==1.23.8\n",
        "# !pip install faiss-gpu==1.7.2\n",
        "# !pip install faiss-cpu==1.7.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#langchain library\n",
        "!pip install langchain\n",
        "#LLM\n",
        "!pip install accelerate\n",
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "#Text Embedding\n",
        "!pip install sentence-transformers\n",
        "!pip install InstructorEmbedding\n",
        "#vectorstore\n",
        "!pip install pymupdf\n",
        "!pip install faiss-cpu\n",
        "!pip install langchain-community\n",
        "!pip install langchain-huggingface"
      ],
      "metadata": {
        "id": "AK1l5ADOeEUb",
        "outputId": "2f329056-732c-4d7a-c010-596987d52e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.0.350)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.13)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.0.4)\n",
            "Collecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1 (from langchain)\n",
            "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
            "  Using cached langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Using cached langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "Installing collected packages: langsmith, langchain-core\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.15\n",
            "    Uninstalling langsmith-0.3.15:\n",
            "      Successfully uninstalled langsmith-0.3.15\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.45\n",
            "    Uninstalling langchain-core-0.3.45:\n",
            "      Successfully uninstalled langchain-core-0.3.45\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-huggingface 0.1.2 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.23 which is incompatible.\n",
            "langchain-text-splitters 0.3.6 requires langchain-core<1.0.0,>=0.3.34, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.1.23 langsmith-0.0.87\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.29.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.49.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.23.8)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.7 in /usr/local/lib/python3.11/dist-packages (from pymupdf) (1.23.7)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.7.4)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.0.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.1.23)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.0.87)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.29.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain-huggingface)\n",
            "  Using cached langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface)\n",
            "  Using cached langsmith-0.3.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Using cached langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
            "Using cached langsmith-0.3.15-py3-none-any.whl (343 kB)\n",
            "Installing collected packages: langsmith, langchain-core\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.87\n",
            "    Uninstalling langsmith-0.0.87:\n",
            "      Successfully uninstalled langsmith-0.0.87\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.1.23\n",
            "    Uninstalling langchain-core-0.1.23:\n",
            "      Successfully uninstalled langchain-core-0.1.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.0.4 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.3.45 which is incompatible.\n",
            "langchain-community 0.0.4 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.3.15 which is incompatible.\n",
            "langchain 0.0.350 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.3.45 which is incompatible.\n",
            "langchain 0.0.350 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.3.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.45 langsmith-0.3.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DWq9zpfhd1cu",
        "outputId": "f89a6d1f-8ac8-47fa-9c02-7b1826fd6bba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "# Set GPU device\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkDYR0oXd1cw"
      },
      "source": [
        "## 1. Prompt\n",
        "\n",
        "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tpw0ud0jd1cw",
        "outputId": "1a58b4dd-0e27-400c-cea1-3f10ec150fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\\n    The current year is 2025, and all answers should reflect this year unless otherwise specified.\\n    Whether you're curious about my education, work experience, or personal interests,\\n    I’ll provide accurate and gentle responses using the information I have.\\n    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "    I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
        "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
        "    Whether you're curious about my education, work experience, or personal interests,\n",
        "    I’ll provide accurate and gentle responses using the information I have.\n",
        "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
        "    {context}\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    \"\"\".strip()\n",
        "\n",
        "PROMPT = PromptTemplate.from_template(\n",
        "    template = prompt_template\n",
        ")\n",
        "\n",
        "PROMPT\n",
        "#using str.format\n",
        "#The placeholder is defined using curly brackets: {} {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xF5zLmjOd1cx",
        "outputId": "b59c13bd-c6c5-4738-bdaa-4df1a2d0d9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\\n    The current year is 2025, and all answers should reflect this year unless otherwise specified.\\n    Whether you're curious about my education, work experience, or personal interests,\\n    I’ll provide accurate and gentle responses using the information I have.\\n    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    My CV states that I graduated with a Bachelor’s degree in Computer Science from University of Information Technology.\\n    Question: What is your highest level of education?\\n    Answer:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "PROMPT.format(\n",
        "    context = \"My CV states that I graduated with a Bachelor’s degree in Computer Science from University of Information Technology.\",\n",
        "    question = \"What is your highest level of education?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Z2dX9Ud1cy"
      },
      "source": [
        "Note : [How to improve prompting (Zero-shot, Few-shot, Chain-of-Thought, etc.](https://github.com/chaklam-silpasuwanchai/Natural-Language-Processing/blob/main/Code/05%20-%20RAG/advance/cot-tot-prompting.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP6d0tIPd1cy"
      },
      "source": [
        "## 2. Retrieval\n",
        "\n",
        "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code).\n",
        "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
        "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
        "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
        "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnaIU_Skd1cy"
      },
      "source": [
        "### 2.1 Document Loaders\n",
        "Use document loaders to load data from a source as Document's. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
        "\n",
        "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)\n",
        "\n",
        "[Download Document](https://web.stanford.edu/~jurafsky/slp3/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZkESZpT4d1cz",
        "outputId": "be18a29f-b62c-433d-a324-db648968d85a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/blob_loaders/file_system.py:5: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_community.document_loaders.blob_loaders.schema import Blob, BlobLoader\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/__init__.py:215: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_community.document_loaders.youtube import (\n"
          ]
        }
      ],
      "source": [
        "# from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "# nlp_docs = '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf'\n",
        "\n",
        "# loader = PyMuPDFLoader(nlp_docs)\n",
        "# documents = loader.load()\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "cv_file = 'data/MyaMjechal-CV.txt'\n",
        "loader = TextLoader(cv_file)\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGy_H2tHd1cz"
      },
      "outputs": [],
      "source": [
        "# documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WsuIjb4Td1cz",
        "outputId": "073fab5d-7a13-4356-8ae2-0fc5de4bad68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Hs-DqktEd1c0",
        "outputId": "58433b1e-6f76-46f1-b1af-f933a5502fbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='Mya Mjechal\\nFull Stack Developer\\n\\nPathum Thani, Thailand\\nmyamjechal.mj@gmail.com\\n\\nBirthday: September 16, 1999\\n\\nI am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\\n\\nPERSONAL INFORMATION\\nAddress: Pathum Thani, Thailand\\nNationality: Burmese\\nDriving License: No\\nHobbies: Reading, watching movies and series, coding, singing and listening to music\\n\\nLANGUAGES\\nBurmese - Native\\nEnglish - Fluent\\nJapanese - N3\\nThai - Beginner\\n\\nSKILLS\\nSelf-motivation, Decision Making, Fast Learner, Problem Solving, Critical Thinking, Teamwork, Customer Service, Adaptability, Computer Skills, Leadership Skills, Communication Skills, Effective Time Management, Attention to Detail, Ability to Work in a Team, Ability to Work Under Pressure, Microsoft Office, Python, Odoo, JavaScript, HTML & CSS, Bootstrap, Java, PHP, Wordpress, Git, Linux, Docker, Node.js, SQL, MySQL, PostgreSQL, Figma & Adobe XD\\n\\nWORK EXPERIENCE\\n\\nJanuary 2025 – Present\\nTechnical Support | intERLab (Asian Institute of Technology)\\nAs a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\\n\\nJanuary 2024 – December 2024\\nSenior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\\nI developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\\n\\nJune 2022 – December 2023\\nComputer Programmer | EduTech Social Enterprise, Yangon\\nI built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\\n\\nSeptember 2020 – March 2022\\nJunior Software Engineer | Bliss Stock Co., Ltd, Japan\\nI maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.\\n\\nEDUCATION\\nAsian Institute of Technology (AIT), Pathum Thani\\nMaster of Science in Data Science and Artificial Intelligence (Expected May 2025)\\nUniversity of Information Technology, Yangon\\nB.C.Sc (High Performance Computing), Graduated 2020\\nKMD Institute, Yangon\\nNCC Level 4 Diploma in Computing, Graduated 2018\\n\\nINTERNSHIPS\\n\\nJune 2020 – August 2020\\nJunior Software Engineer | Bliss Stock Co., Ltd.\\nDeveloped an e-commerce mobile app with Flutter, Firebase, and Algolia.\\n\\nACTIVITIES\\n\\nCommittee Member (Gender and Culture Committee of AIT Student Union), January 2025 – Present\\n\\nVolunteer Project Coordinator (Career Readiness Program), Yangon, January 2023 – July 2023\\n\\nADDITIONAL INFORMATION\\n\\nAge: 25 years old (as of 2025)\\n\\nHighest Level of Education: Master of Science (Expected May 2025)\\n\\nMajor: Data Science and Artificial Intelligence\\n\\nWork Experience: Over 4 years in software development, full-stack development, and technical support\\n\\nIndustries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\\n\\nCurrent Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\\n\\nCore Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\\n\\nCultural Values in Technology: Cultural values should be respected and incorporated into technological advancements to ensure inclusivity and fairness.\\n\\nChallenges in Master’s Studies: Managing multiple deadlines, balancing coursework with part-time work, and handling computational limitations.\\n\\nResearch Interests and Academic Goals: NLP, AI ethics, and computational efficiency in machine translation and big data analysis.\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zx7b9eUd1c0"
      },
      "source": [
        "### 2.2 Document Transformers\n",
        "\n",
        "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "t2Q3HGrKd1c1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 700,\n",
        "    chunk_overlap = 100\n",
        ")\n",
        "\n",
        "doc = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M8kE0hKRd1c2",
        "outputId": "785264b1-b9f2-494d-fb1d-020914ae89fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "doc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JYLO1upud1c3",
        "outputId": "c532d5ae-3db3-4f90-b3f4-a977aeda772c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irj_OjF4d1c4"
      },
      "source": [
        "### 2.3 Text Embedding Models\n",
        "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
        "\n",
        "*Note* Instructor Model : [Huggingface](gingface.co/hkunlp/instructor-base) | [Paper](https://arxiv.org/abs/2212.09741)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FJKq7oKUd1c4",
        "outputId": "c1fa4285-d810-47da-bb65-1d9e26093b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "3a29eb59454941b9944ba065bb9e8c18",
            "a14592db94ee48d78d1df159f91a2b8c",
            "84c785c2a39444849e13be49f34ea612",
            "c22744991128444a8b85bc2df50eab3d",
            "d132d7e2ba99430597bc3a19572e9a39",
            "4f985afcdde8443cb4d7ce2adfc60c6e",
            "02008f67aeac438a959d6028f214400a",
            "98d0f3e73768459281266caa6c206abf",
            "e669ed37df974ab291e65b8580bbb3de",
            "d3ff41ffb67e4dccb601d97b2076dc01",
            "1d39d00ed41f4759ab95cdc41f7d726d",
            "7873f25bf18d4512838da390f4bd9053",
            "2dbc15bcde1f443aa3c3e126793cb77a",
            "501e5a75250e4f1c95ebc05fb615b3e8",
            "bc9dec83f60d44e69c9d32a4455ece66",
            "304d18c705274411a79e95bb491b5e52",
            "a5c22bc257b045c4b68a0a70c2b3750f",
            "46eeb4d5b13b427283693439954f201e",
            "5f9fa454bcab46a8a622fe078dd10206",
            "b6d641f53308440c8b56f6b1202e111c",
            "77b26d78c9af44088368aa4ad381438e",
            "84ae50655cd74d68ad658823a005a3e5",
            "2807656cb31344dda1ea10f0554f5958",
            "59181b1df9354330b13b3acf7fcb34d8",
            "4a7a5f877e834f4abe7982a4ba6da22c",
            "4ebf1ad73a604171a023e41c03b278b0",
            "0a666fb05ea84948b9a8bae8feb004ec",
            "d7ab3a4c45814361a6f325a8c52d639e",
            "0eb9c9d45c004508a4e063e19bfc6a39",
            "2c54f3b6a87d424ab9382031f75b4dfc",
            "3e70e3a55be14d5e89112d15c01f9ec5",
            "d903c9bf14004d3ebb972eabdcab7b32",
            "f31bd457bc4645b3af6dfee0367e1333",
            "95949b82a9bc4da5b3b5aa6c10867d5f",
            "708c927435b04113838c258e37baf0f8",
            "8fab9b5bb94645b197bf5119118c082c",
            "1d1b677a7fec427685d97d1c9ff7fb6c",
            "171e70e03baa41de8922fdcdd1231973",
            "5555cae32c96451c98d8c0d207db59d5",
            "c42375258df14c80a5540526c74d9857",
            "c7cc9056f9e64073b544f4d5f1290e42",
            "861bed8accb24d59b31d02b619f622e2",
            "98d1ef7a54a149dc9270ddeec536c55f",
            "4b942049eab34417883c1f1ec4588b03",
            "4af4faa13f3143f7a0f5f676838f5b51",
            "ac82c83586a64337996bd9196a12a050",
            "c644688513d3420c802abbe34cebd584",
            "c0e8a6976bcd4e12a4c472398d472a3a",
            "4e7d7362188e42fca123b5075797061d",
            "4a78f8d194c0496a9e843e2fdd3a0298",
            "e0f96f76eaf44a80a7a25350f30809d9",
            "805134c03ba14653a4feff008d00771a",
            "2d112fcf113f4100ba5c4c37a984618b",
            "bb79fce4fae74b8285eef333c5f7bc77",
            "de619b94fab142169b70ff74d16854b9",
            "ab0b78f473154a5c87d8ca07c7f0e287",
            "b5c97e53ca4a4e28b53dd6f13f8bebaa",
            "33edc46ed7ea4db08ff98e7e315511a7",
            "d8feceda4f6845ef8a0c75ed1ead81fb",
            "481434e222a64c09a9581debf32a6f67",
            "a128af895b764911af827161f00f031a",
            "4b480e7015744449aea6139ecd538887",
            "b3f431ae3fab466abbd8f4d7d805f334",
            "ba395d8269644cfdb126925d53176044",
            "6295f7a556f94748826e00abc5841150",
            "dd5bc290b7b8443591f961d69055fcb3",
            "84a7bf4bf3534fc8857c352e727330b0",
            "66cb3715035641f6880c42a038defa6b",
            "7e1e0fcc1f0e4450910b2fa257723a16",
            "498c2800fcf14e059edb334e76c124aa",
            "1231873fe28b4db69b87decbf9897fdb",
            "66a73d0ba8b34b3f8de26b979bbcff1d",
            "ac91c2521a1245ed82e2c15b82e8328e",
            "8f1d9e384eb94bd9949199626067f2cf",
            "3a299a4b4d5444c6a11e5a5e48c2b48a",
            "7580c03d32b340579e141f56bde9fe61",
            "58ac40b3345343ac91e756a76148e0b6",
            "6de11dfa87ee4de287dab727b6733477",
            "51c215e80c8a470085aa16be4591ffff",
            "1fd09386009e44c19b4d51ad8f2dba1e",
            "cd084e7bb2fa428492e63b113552d11e",
            "3e20b33f66b6424382fc5e34524a3d0d",
            "a96d7c53ba3c40be99317dda013bd486",
            "b6043692908f4293a8e7f23c02cf043a",
            "bc79201cb33b460f89a7f864c9c6e36e",
            "716a5939a0954bb3b9acf24c1a17c8c8",
            "b68075b0bc4a46018af40890112e4a08",
            "a2a78fc59f3942ae97686bc517f3c6d9",
            "68c3d88fa3b345009a6d594f3fa4db24",
            "e2843989dfb4442cad13cb068f5d0c8b",
            "23cabbef947c428095b03827e56e8062",
            "1162fd57e9254b7dac10e6ad8bfc8e22",
            "d6c0f0f4ce5143cea81b3986f8525d94",
            "0e136238969a40b28fb68023a7cefd3c",
            "ce07010d2595417ebbcef94859341765",
            "b608d586a3c24ff0b3f7bf907b605245",
            "7443a33abe924a53a895f224fc324c58",
            "3b147cd74ecb45ac9291c0b0e8c5f6cc",
            "54586540a25d4b01b2186d2e91600132",
            "3711f39099c34abb96d00b06b1ae0b36",
            "7de613efa0c1469d9cc1469d3117e72d",
            "d5d5839835a34375b8c0c22006947668",
            "5b194de0b0d64565b713c256038dbac4",
            "9c64d349d8744ed3ace77b6ac10a6abc",
            "80ef30acb7c64e15830242bb90b00428",
            "049f159746d44a999b42059813f8081a",
            "a91d0851b1e84cb58b8cd5145b8a8d69",
            "e7c9120e208046c897aab24c4b03163a",
            "10147b15dd474fdbab4bdbbe31a74c3b",
            "d4eca018c3674380bfeb98c444442136",
            "d2ee7c0e955d439e8ad68e28be9f40d9",
            "cdfdade1a27b47169da39e592546351c",
            "88a85cd8b0244123b971f31aee8e5eb8",
            "c7b70a10767a45e1b360b9325af11165",
            "3c8af24f3d65462a8ca90b3f94bc1013",
            "de5bda4789c34fb7a4fdba9036923236",
            "514d16c8a42c40e69b4ce59f399fd5ec",
            "50203dede23b45d69bf8dc1680f49aa2",
            "b8c9f625daff48b7ae85a33b9f73f892",
            "aaba50955b03423483b29929d6c12cab",
            "244b8408b5934bc39cdcf650bb24c532"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a29eb59454941b9944ba065bb9e8c18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7873f25bf18d4512838da390f4bd9053"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2807656cb31344dda1ea10f0554f5958"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95949b82a9bc4da5b3b5aa6c10867d5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4af4faa13f3143f7a0f5f676838f5b51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab0b78f473154a5c87d8ca07c7f0e287"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84a7bf4bf3534fc8857c352e727330b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6de11dfa87ee4de287dab727b6733477"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68c3d88fa3b345009a6d594f3fa4db24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3711f39099c34abb96d00b06b1ae0b36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2ee7c0e955d439e8ad68e28be9f40d9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "# from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name = model_name,\n",
        "    model_kwargs = {\"device\" : device}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLmyUKOid1c5"
      },
      "source": [
        "### 2.4 Vector Stores\n",
        "\n",
        "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "f3HdjnBGd1c5"
      },
      "outputs": [],
      "source": [
        "#locate vectorstore\n",
        "vector_path = '../vector-store'\n",
        "if not os.path.exists(vector_path):\n",
        "    os.makedirs(vector_path)\n",
        "    print('create path done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wWT2Bxezd1c5"
      },
      "outputs": [],
      "source": [
        "#save vector locally\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectordb = FAISS.from_documents(\n",
        "    documents = doc,\n",
        "    embedding = embedding_model\n",
        ")\n",
        "\n",
        "db_file_name = 'myamjechal_cv'\n",
        "\n",
        "vectordb.save_local(\n",
        "    folder_path = os.path.join(vector_path, db_file_name),\n",
        "    index_name = 'cv' #default index\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVQ8EUiJd1c5"
      },
      "source": [
        "### 2.5 retrievers\n",
        "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WDF7RSdnd1c5"
      },
      "outputs": [],
      "source": [
        "#calling vector from local\n",
        "vector_path = '../vector-store'\n",
        "db_file_name = 'myamjechal_cv'\n",
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectordb = FAISS.load_local(\n",
        "    folder_path = os.path.join(vector_path, db_file_name),\n",
        "    embeddings = embedding_model,\n",
        "    index_name = 'cv' #default index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S0hNjmvXd1c6"
      },
      "outputs": [],
      "source": [
        "#ready to use\n",
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "B2rhHLADd1c6",
        "outputId": "26bdc533-1426-4f95-8da9-9c8d82776419",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-50d30f9d0dc1>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  retriever.get_relevant_documents(\"What is your name?\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='Mya Mjechal\\nFull Stack Developer\\n\\nPathum Thani, Thailand\\nmyamjechal.mj@gmail.com\\n\\nBirthday: September 16, 1999'),\n",
              " Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='PERSONAL INFORMATION\\nAddress: Pathum Thani, Thailand\\nNationality: Burmese\\nDriving License: No\\nHobbies: Reading, watching movies and series, coding, singing and listening to music\\n\\nLANGUAGES\\nBurmese - Native\\nEnglish - Fluent\\nJapanese - N3\\nThai - Beginner'),\n",
              " Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='WORK EXPERIENCE\\n\\nJanuary 2025 – Present\\nTechnical Support | intERLab (Asian Institute of Technology)\\nAs a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\\n\\nJanuary 2024 – December 2024\\nSenior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\\nI developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.'),\n",
              " Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='EDUCATION\\nAsian Institute of Technology (AIT), Pathum Thani\\nMaster of Science in Data Science and Artificial Intelligence (Expected May 2025)\\nUniversity of Information Technology, Yangon\\nB.C.Sc (High Performance Computing), Graduated 2020\\nKMD Institute, Yangon\\nNCC Level 4 Diploma in Computing, Graduated 2018\\n\\nINTERNSHIPS\\n\\nJune 2020 – August 2020\\nJunior Software Engineer | Bliss Stock Co., Ltd.\\nDeveloped an e-commerce mobile app with Flutter, Firebase, and Algolia.\\n\\nACTIVITIES\\n\\nCommittee Member (Gender and Culture Committee of AIT Student Union), January 2025 – Present\\n\\nVolunteer Project Coordinator (Career Readiness Program), Yangon, January 2023 – July 2023\\n\\nADDITIONAL INFORMATION')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "retriever.get_relevant_documents(\"What is your name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WbkooMRFd1c6",
        "outputId": "33eb42ef-96db-46a0-bdee-3eae46d44ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='ADDITIONAL INFORMATION\\n\\nAge: 25 years old (as of 2025)\\n\\nHighest Level of Education: Master of Science (Expected May 2025)\\n\\nMajor: Data Science and Artificial Intelligence\\n\\nWork Experience: Over 4 years in software development, full-stack development, and technical support\\n\\nIndustries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\\n\\nCurrent Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\\n\\nCore Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.'),\n",
              " Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='June 2022 – December 2023\\nComputer Programmer | EduTech Social Enterprise, Yangon\\nI built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\\n\\nSeptember 2020 – March 2022\\nJunior Software Engineer | Bliss Stock Co., Ltd, Japan\\nI maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.'),\n",
              " Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='Mya Mjechal\\nFull Stack Developer\\n\\nPathum Thani, Thailand\\nmyamjechal.mj@gmail.com\\n\\nBirthday: September 16, 1999'),\n",
              " Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='WORK EXPERIENCE\\n\\nJanuary 2025 – Present\\nTechnical Support | intERLab (Asian Institute of Technology)\\nAs a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\\n\\nJanuary 2024 – December 2024\\nSenior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\\nI developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "retriever.get_relevant_documents(\"How old are you?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPH3kUaad1c7"
      },
      "source": [
        "## 3. Memory\n",
        "\n",
        "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
        "\n",
        "You may want to use this class directly if you are managing memory outside of a chain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KUAJvK6Fd1c7",
        "outputId": "f31b7b45-e2bb-4543-cef5-5a8e78ffd053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/v1/validators.py:767: UserWarning: Mixing V1 and V2 models is not supported. `BaseMessage` is a V2 model.\n",
            "  warn(f'Mixing V1 and V2 models is not supported. `{type_.__name__}` is a V2 model.', UserWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "no validator found for <class 'langchain_core.messages.base.BaseMessage'>, see `arbitrary_types_allowed` in Config",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-575f16f48dd3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatMessageHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a ChatMessageHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatMessageHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/memory/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/_api/module_import.py\u001b[0m in \u001b[0;36mimport_by_name\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chat_message_histories/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mFirestoreChatMessageHistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_message_histories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_memory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatMessageHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_message_histories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomento\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMomentoChatMessageHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_message_histories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmongodb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMongoDBChatMessageHistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/chat_message_histories/in_memory.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mChatMessageHistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseChatMessageHistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \"\"\"In memory implementation of chat message history.\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/main.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     ):\n\u001b[1;32m    196\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                     fields[ann_name] = ModelField.infer(\n\u001b[0m\u001b[1;32m    198\u001b[0m                         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mann_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                         \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_annotation_from_field_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_assignment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         return cls(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHAPE_SINGLETON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUndefined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m_type_analysis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# type_ has been refined eg. as the type of a List and sub_fields needs to be populated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_sub_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_discriminated_union_sub_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m_create_sub_type\u001b[0;34m(self, type_, name, for_keys)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0mfield_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         return self.__class__(\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSHAPE_SINGLETON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_field\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mUndefined\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_default_and_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/fields.py\u001b[0m in \u001b[0;36mpopulate_validators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m             v_funcs = (\n\u001b[1;32m    828\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_validators_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meach_item\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m                 \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mget_validators\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_validators_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meach_item\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/v1/validators.py\u001b[0m in \u001b[0;36mfind_validators\u001b[0;34m(type_, config)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__pydantic_core_schema__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mixing V1 and V2 models is not supported. `{type_.__name__}` is a V2 model.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'no validator found for {type_}, see `arbitrary_types_allowed` in Config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: no validator found for <class 'langchain_core.messages.base.BaseMessage'>, see `arbitrary_types_allowed` in Config"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "# Create a ChatMessageHistory\n",
        "history = ChatMessageHistory()\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS_gSl37d1c7"
      },
      "outputs": [],
      "source": [
        "history.add_user_message('hi')\n",
        "history.add_ai_message('Whats up?')\n",
        "history.add_user_message('How are you')\n",
        "history.add_ai_message('I\\'m quite good. How about you?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHtCmRmWd1c8",
        "outputId": "507daeef-a9f4-4b13-c45c-60b50e598a9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvdPmrD-d1c8"
      },
      "source": [
        "### 3.1 Memory types\n",
        "\n",
        "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios.\n",
        "- Converstaion Buffer\n",
        "- Converstaion Buffer Window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArhgBq0Fd1c9"
      },
      "source": [
        "What variables get returned from memory\n",
        "\n",
        "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPzbQnDtd1c9"
      },
      "source": [
        "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZUyiQ9Md1c9"
      },
      "source": [
        "#### Converstaion Buffer\n",
        "This memory allows for storing messages and then extracts the messages in a variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pkzCh3td1c9",
        "outputId": "42f92359-71bd-4ab7-a6d8-7a4e9a04a2b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGKjQ9Vad1c9",
        "outputId": "7111fcde-a27e-4a15-a11c-c2834b1522a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='hi'),\n",
              "  AIMessage(content=\"What's up?\"),\n",
              "  HumanMessage(content='How are you?'),\n",
              "  AIMessage(content=\"I'm quite good. How about you?\")]}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages = True)\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfsvnD4Rd1c-"
      },
      "source": [
        "#### Conversation Buffer Window\n",
        "- it keeps a list of the interactions of the conversation over time.\n",
        "- it only uses the last K interactions.\n",
        "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mle6OBNod1c-",
        "outputId": "b0da6460-a7df-4930-aba9-aeaa9d34bc97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkXxfhWWd1c-"
      },
      "source": [
        "## 4. Chain\n",
        "\n",
        "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
        "\n",
        "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
        "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
        "- it formats the prompt template using the input key values provided (and also memory key values, if available),\n",
        "- it passes the formatted string to LLM and returns the LLM output.\n",
        "\n",
        "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvCWJaqNd1c_"
      },
      "outputs": [],
      "source": [
        "# %cd ./models\n",
        "# !git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xQR2Ba0d1c_",
        "outputId": "fa030b3a-3272-41df-a19d-d02a5d116a3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-02 14:57:27.374664: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-02 14:57:27.392320: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-02 14:57:27.392344: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-02 14:57:27.392979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-02 14:57:27.396491: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-02 14:57:27.688556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
        "from transformers import BitsAndBytesConfig\n",
        "from langchain import HuggingFacePipeline\n",
        "import torch\n",
        "\n",
        "model_id = '../models/fastchat-t5-3b-v1.0/'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id)\n",
        "\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "bitsandbyte_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "    bnb_4bit_compute_dtype = torch.float16,\n",
        "    bnb_4bit_use_double_quant = True\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config = bitsandbyte_config, #caution Nvidia\n",
        "    device_map = 'auto',\n",
        "    load_in_8bit = True\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    task=\"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens = 256,\n",
        "    model_kwargs = {\n",
        "        \"temperature\" : 0,\n",
        "        \"repetition_penalty\": 1.5\n",
        "    }\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline = pipe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt34O9_Fd1c_"
      },
      "source": [
        "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
        "\n",
        "- `retriever` : Retriever to use to fetch documents.\n",
        "\n",
        "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
        "\n",
        "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
        "\n",
        "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
        "\n",
        "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
        "\n",
        "- `return_generated_question` : Return the generated question as part of the final result.\n",
        "\n",
        "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDz3ED7Kd1c_"
      },
      "source": [
        "`question_generator`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d--xD9zpd1dA"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VA6oKD8Ed1dA",
        "outputId": "6b9fb907-cff3-4611-8260-7b09ea6d81e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CONDENSE_QUESTION_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sHwvEH7d1dA"
      },
      "outputs": [],
      "source": [
        "question_generator = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = CONDENSE_QUESTION_PROMPT,\n",
        "    verbose = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0aubOwcd1dA",
        "outputId": "435862e0-add5-4d1f-87ec-5d58091b0032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "Human:What is Machine Learning\n",
            "AI:\n",
            "Human:What is Deep Learning\n",
            "AI:\n",
            "Follow Up Input: Comparing Both of them\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'chat_history': 'Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:',\n",
              " 'question': 'Comparing Both of them',\n",
              " 'text': '<pad> What  is  the  difference  between  Machine  Learning  and  Deep  Learning  AI?\\n'}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'Comparing both of them'\n",
        "chat_history = \"Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:\"\n",
        "\n",
        "question_generator({'chat_history' : chat_history, \"question\" : query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnFvfKt_d1dB"
      },
      "source": [
        "`combine_docs_chain`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf8RqfI6d1dB",
        "outputId": "7a225ed8-7b01-4de0-f9bb-1bdc761d1f49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), document_variable_name='context')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc_chain = load_qa_chain(\n",
        "    llm = llm,\n",
        "    chain_type = 'stuff',\n",
        "    prompt = PROMPT,\n",
        "    verbose = True\n",
        ")\n",
        "doc_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Oo6VpwXOd1dB",
        "outputId": "1a8c7270-c782-482c-a491-c18b907f800c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
            "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
            "    Whether it's about probabilistic models, language models, or any other related topic, \n",
            "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
            "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    formers are not based on recurrent connections (which can be hard to parallelize),\n",
            "which means that transformers can be more efﬁcient to implement at scale.\n",
            "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
            "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
            "former blocks, each of which is a multilayer network made by combining simple\n",
            "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
            "self-attention\n",
            "transformers. Self-attention allows a network to directly extract and use information\n",
            "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
            "\n",
            "multaneously. For example, distinct syntactic, semantic, and discourse relationships\n",
            "can hold between verbs and their arguments in a sentence. It would be difﬁcult for\n",
            "a single transformer block to learn to capture all of the different kinds of parallel\n",
            "relations among its inputs. Transformers address this issue with multihead self-\n",
            "attention layers. These are sets of self-attention layers, called heads, that reside in\n",
            "multihead\n",
            "self-attention\n",
            "layers\n",
            "parallel layers at the same depth in a model, each with its own set of parameters.\n",
            "\n",
            "214\n",
            "CHAPTER 10\n",
            "•\n",
            "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
            "• As the current focus of attention when being compared to all of the other\n",
            "preceding inputs. We’ll refer to this role as a query.\n",
            "query\n",
            "• In its role as a preceding input being compared to the current focus of atten-\n",
            "tion. We’ll refer to this role as a key.\n",
            "key\n",
            "• And ﬁnally, as a value used to compute the output for the current focus of\n",
            "value\n",
            "attention.\n",
            "To capture these three different roles, transformers introduce weight matrices\n",
            "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
            "a representation of its role as a key, query, or value.\n",
            "qi = WQxi; ki = WKxi; vi = WVxi\n",
            "(10.5)\n",
            "\n",
            "transformer\n",
            "The transformer offers new mechanisms (self-attention and positional encod-\n",
            "ings) that help represent time and help focus on how words relate to each other over\n",
            "long distances. We’ll see how to apply this model to the task of language modeling,\n",
            "and then we’ll see how a transformer pretrained on language modeling can be used\n",
            "in a zero shot manner to perform other NLP tasks.\n",
            "10.1\n",
            "Self-Attention Networks: Transformers\n",
            "In this section we introduce the architecture of transformers. Like the LSTMs of\n",
            "transformers\n",
            "Chapter 9, transformers can handle distant information. But unlike LSTMs, trans-\n",
            "formers are not based on recurrent connections (which can be hard to parallelize),\n",
            "    Question: What is Transformers?\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_documents': [Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})],\n",
              " 'question': 'What is Transformers?',\n",
              " 'output_text': '<pad>  A  type  of  neural  network  architecture  that  maps  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  Transformers  are  made  up  of  stacks  of  trans-\\n'}"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What is Transformers?\"\n",
        "input_document = retriever.get_relevant_documents(query)\n",
        "\n",
        "doc_chain({'input_documents':input_document, 'question':query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "po2GMMnXd1dB",
        "outputId": "0eb8404d-10a5-42da-9d9a-76a51d552920"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template=\"I'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \\n    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \\n    Whether it's about probabilistic models, language models, or any other related topic, \\n    I'm here to help break down complex concepts into easy-to-understand explanations.\\n    Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x7fefa8f7ec50>)), return_source_documents=True, get_chat_history=<function <lambda> at 0x7fef45fef400>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fefaad30b50>))"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    k=3,\n",
        "    memory_key = \"chat_history\",\n",
        "    return_messages = True,\n",
        "    output_key = 'answer'\n",
        ")\n",
        "\n",
        "chain = ConversationalRetrievalChain(\n",
        "    retriever=retriever,\n",
        "    question_generator=question_generator,\n",
        "    combine_docs_chain=doc_chain,\n",
        "    return_source_documents=True,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    get_chat_history=lambda h : h\n",
        ")\n",
        "chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg5Xtq1Td1dC"
      },
      "source": [
        "## 5. Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHmLW1v_d1dC",
        "outputId": "bf0437a9-dbec-4d4e-e649-bb06a4db4654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
            "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
            "    Whether it's about probabilistic models, language models, or any other related topic, \n",
            "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
            "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    in this way are also called complementizers.\n",
            "complementizer\n",
            "Pronouns act as a shorthand for referring to an entity or event. Personal pro-\n",
            "pronoun\n",
            "nouns refer to persons or entities (you, she, I, it, me, etc.). Possessive pronouns are\n",
            "forms of personal pronouns that indicate either actual possession or more often just\n",
            "an abstract relation between the person and some object (my, your, his, her, its, one’s,\n",
            "our, their). Wh-pronouns (what, who, whom, whoever) are used in certain question\n",
            "wh\n",
            "\n",
            "EXERCISES\n",
            "57\n",
            "<s> I am Sam </s>\n",
            "<s> Sam I am </s>\n",
            "<s> I am Sam </s>\n",
            "<s> I do not like green eggs and Sam </s>\n",
            "Using a bigram language model with add-one smoothing, what is P(Sam |\n",
            "am)? Include <s> and </s> in your counts just like any other token.\n",
            "3.5\n",
            "Suppose we didn’t use the end-symbol </s>. Train an unsmoothed bigram\n",
            "grammar on the following training corpus without using the end-symbol </s>:\n",
            "<s> a b\n",
            "<s> b b\n",
            "<s> b a\n",
            "<s> a a\n",
            "Demonstrate that your bigram model does not assign a single probability dis-\n",
            "tribution across all sentence lengths by showing that the sum of the probability\n",
            "of the four possible 2 word sentences over the alphabet {a,b} is 1.0, and the\n",
            "\n",
            "through two millennia speaks to their centrality in models of human language.\n",
            "Proper names are another important and anciently studied linguistic category.\n",
            "While parts of speech are generally assigned to individual words or morphemes, a\n",
            "proper name is often an entire multiword phrase, like the name “Marie Curie”, the\n",
            "location “New York City”, or the organization “Stanford University”. We’ll use the\n",
            "term named entity for, roughly speaking, anything that can be referred to with a\n",
            "named entity\n",
            "proper name: a person, a location, an organization, although as we’ll see the term is\n",
            "commonly extended to include things that aren’t entities per se.\n",
            "\n",
            "15.2\n",
            "•\n",
            "CHATBOTS\n",
            "303\n",
            "Men are all alike.\n",
            "IN WHAT WAY\n",
            "They’re always bugging us about something or other.\n",
            "CAN YOU THINK OF A SPECIFIC EXAMPLE\n",
            "Well my boyfriend made me come here.\n",
            "YOUR BOYFRIEND MADE YOU COME HERE\n",
            "He says I’m depressed much of the time.\n",
            "I AM SORRY TO HEAR YOU ARE DEPRESSED\n",
            "....\n",
            "WHO ELSE IN YOUR FAMILY TAKES CARE OF YOU?\n",
            "My father\n",
            "YOUR FATHER\n",
            "You are like my father in some ways.\n",
            "WHAT RESEMBLANCE DO YOU SEE\n",
            "You are not very aggressive but I think you don’t want me to notice that.\n",
            "WHAT MAKES YOU THINK I AM NOT AGGRESSIVE\n",
            "You don’t argue with me.\n",
            "WHY DO YOU THINK I DON’T ARGUE WITH YOU\n",
            "You are afraid of me.\n",
            "DOES IT PLEASE YOU TO BELIEVE I’M AFRAID OF YOU\n",
            "    Question: Who are you by the way?\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'Who are you by the way?',\n",
              " 'chat_history': [],\n",
              " 'answer': '<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ',\n",
              " 'source_documents': [Document(page_content='in this way are also called complementizers.\\ncomplementizer\\nPronouns act as a shorthand for referring to an entity or event. Personal pro-\\npronoun\\nnouns refer to persons or entities (you, she, I, it, me, etc.). Possessive pronouns are\\nforms of personal pronouns that indicate either actual possession or more often just\\nan abstract relation between the person and some object (my, your, his, her, its, one’s,\\nour, their). Wh-pronouns (what, who, whom, whoever) are used in certain question\\nwh', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 169, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='EXERCISES\\n57\\n<s> I am Sam </s>\\n<s> Sam I am </s>\\n<s> I am Sam </s>\\n<s> I do not like green eggs and Sam </s>\\nUsing a bigram language model with add-one smoothing, what is P(Sam |\\nam)? Include <s> and </s> in your counts just like any other token.\\n3.5\\nSuppose we didn’t use the end-symbol </s>. Train an unsmoothed bigram\\ngrammar on the following training corpus without using the end-symbol </s>:\\n<s> a b\\n<s> b b\\n<s> b a\\n<s> a a\\nDemonstrate that your bigram model does not assign a single probability dis-\\ntribution across all sentence lengths by showing that the sum of the probability\\nof the four possible 2 word sentences over the alphabet {a,b} is 1.0, and the', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 64, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='through two millennia speaks to their centrality in models of human language.\\nProper names are another important and anciently studied linguistic category.\\nWhile parts of speech are generally assigned to individual words or morphemes, a\\nproper name is often an entire multiword phrase, like the name “Marie Curie”, the\\nlocation “New York City”, or the organization “Stanford University”. We’ll use the\\nterm named entity for, roughly speaking, anything that can be referred to with a\\nnamed entity\\nproper name: a person, a location, an organization, although as we’ll see the term is\\ncommonly extended to include things that aren’t entities per se.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 167, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='15.2\\n•\\nCHATBOTS\\n303\\nMen are all alike.\\nIN WHAT WAY\\nThey’re always bugging us about something or other.\\nCAN YOU THINK OF A SPECIFIC EXAMPLE\\nWell my boyfriend made me come here.\\nYOUR BOYFRIEND MADE YOU COME HERE\\nHe says I’m depressed much of the time.\\nI AM SORRY TO HEAR YOU ARE DEPRESSED\\n....\\nWHO ELSE IN YOUR FAMILY TAKES CARE OF YOU?\\nMy father\\nYOUR FATHER\\nYou are like my father in some ways.\\nWHAT RESEMBLANCE DO YOU SEE\\nYou are not very aggressive but I think you don’t want me to notice that.\\nWHAT MAKES YOU THINK I AM NOT AGGRESSIVE\\nYou don’t argue with me.\\nWHY DO YOU THINK I DON’T ARGUE WITH YOU\\nYou are afraid of me.\\nDOES IT PLEASE YOU TO BELIEVE I’M AFRAID OF YOU', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 310, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_question = \"Who are you by the way?\"\n",
        "answer = chain({\"question\":prompt_question})\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUOZu-wGd1dD",
        "outputId": "b12f173f-d9c9-4d5d-d06d-f7b19e1561ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Who are you by the way?'), AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ')]\n",
            "Follow Up Input: What is the Transformers?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
            "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
            "    Whether it's about probabilistic models, language models, or any other related topic, \n",
            "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
            "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    formers are not based on recurrent connections (which can be hard to parallelize),\n",
            "which means that transformers can be more efﬁcient to implement at scale.\n",
            "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
            "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
            "former blocks, each of which is a multilayer network made by combining simple\n",
            "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
            "self-attention\n",
            "transformers. Self-attention allows a network to directly extract and use information\n",
            "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
            "\n",
            "multaneously. For example, distinct syntactic, semantic, and discourse relationships\n",
            "can hold between verbs and their arguments in a sentence. It would be difﬁcult for\n",
            "a single transformer block to learn to capture all of the different kinds of parallel\n",
            "relations among its inputs. Transformers address this issue with multihead self-\n",
            "attention layers. These are sets of self-attention layers, called heads, that reside in\n",
            "multihead\n",
            "self-attention\n",
            "layers\n",
            "parallel layers at the same depth in a model, each with its own set of parameters.\n",
            "\n",
            "transformer\n",
            "The transformer offers new mechanisms (self-attention and positional encod-\n",
            "ings) that help represent time and help focus on how words relate to each other over\n",
            "long distances. We’ll see how to apply this model to the task of language modeling,\n",
            "and then we’ll see how a transformer pretrained on language modeling can be used\n",
            "in a zero shot manner to perform other NLP tasks.\n",
            "10.1\n",
            "Self-Attention Networks: Transformers\n",
            "In this section we introduce the architecture of transformers. Like the LSTMs of\n",
            "transformers\n",
            "Chapter 9, transformers can handle distant information. But unlike LSTMs, trans-\n",
            "formers are not based on recurrent connections (which can be hard to parallelize),\n",
            "\n",
            "214\n",
            "CHAPTER 10\n",
            "•\n",
            "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
            "• As the current focus of attention when being compared to all of the other\n",
            "preceding inputs. We’ll refer to this role as a query.\n",
            "query\n",
            "• In its role as a preceding input being compared to the current focus of atten-\n",
            "tion. We’ll refer to this role as a key.\n",
            "key\n",
            "• And ﬁnally, as a value used to compute the output for the current focus of\n",
            "value\n",
            "attention.\n",
            "To capture these three different roles, transformers introduce weight matrices\n",
            "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
            "a representation of its role as a key, query, or value.\n",
            "qi = WQxi; ki = WKxi; vi = WVxi\n",
            "(10.5)\n",
            "    Question: <pad> What  is  the  Transformers?\n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the Transformers?',\n",
              " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
              "  AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train ')],\n",
              " 'answer': '<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ',\n",
              " 'source_documents': [Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='multaneously. For example, distinct syntactic, semantic, and discourse relationships\\ncan hold between verbs and their arguments in a sentence. It would be difﬁcult for\\na single transformer block to learn to capture all of the different kinds of parallel\\nrelations among its inputs. Transformers address this issue with multihead self-\\nattention layers. These are sets of self-attention layers, called heads, that reside in\\nmultihead\\nself-attention\\nlayers\\nparallel layers at the same depth in a model, each with its own set of parameters.', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 224, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='transformer\\nThe transformer offers new mechanisms (self-attention and positional encod-\\nings) that help represent time and help focus on how words relate to each other over\\nlong distances. We’ll see how to apply this model to the task of language modeling,\\nand then we’ll see how a transformer pretrained on language modeling can be used\\nin a zero shot manner to perform other NLP tasks.\\n10.1\\nSelf-Attention Networks: Transformers\\nIn this section we introduce the architecture of transformers. Like the LSTMs of\\ntransformers\\nChapter 9, transformers can handle distant information. But unlike LSTMs, trans-\\nformers are not based on recurrent connections (which can be hard to parallelize),', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_question = \"What is the Transformers?\"\n",
        "answer = chain({\"question\":prompt_question})\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5mmMzATd1dD",
        "outputId": "c6539cbf-fbe9-4d3a-ed00-163996874000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Who are you by the way?'), AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train '), HumanMessage(content='What is the Transformers?'), AIMessage(content='<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ')]\n",
            "Follow Up Input: Is it a statistical model?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named ChakyBot, here to assist Chaky and Gun with any questions they have about Natural Language Processing (NLP). \n",
            "    If you're curious about how probability works in the context of NLP, feel free to ask any questions you may have. \n",
            "    Whether it's about probabilistic models, language models, or any other related topic, \n",
            "    I'm here to help break down complex concepts into easy-to-understand explanations.\n",
            "    Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    sequence, i.e. the target string with the highest probability. Fig. 10.8 demonstrates\n",
            "the problem, using a made-up example. Notice that the most probable sequence is\n",
            "ok ok </s> (with a probability of .4*.7*1.0), but a greedy search algorithm will fail\n",
            "to ﬁnd it, because it incorrectly chooses yes as the ﬁrst word since it has the highest\n",
            "local probability.\n",
            "start\n",
            "ok\n",
            "yes\n",
            "</s>\n",
            "ok\n",
            "yes\n",
            "</s>\n",
            "ok\n",
            "yes\n",
            "</s>\n",
            "</s>\n",
            "</s>\n",
            "</s>\n",
            "</s>\n",
            "t2\n",
            "t3\n",
            "p(t1|start)\n",
            "t1\n",
            "p(t2| t1)\n",
            "p(t3| t1,t2)\n",
            ".1\n",
            ".5\n",
            ".4\n",
            ".2\n",
            ".4\n",
            ".3\n",
            ".1\n",
            ".2\n",
            ".7\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "Figure 10.8\n",
            "A search tree for generating the target string T = t1,t2,... from the vocabulary\n",
            "V = {yes,ok,<s>}, showing the probability of generating each token from that state. Greedy\n",
            "\n",
            "formers are not based on recurrent connections (which can be hard to parallelize),\n",
            "which means that transformers can be more efﬁcient to implement at scale.\n",
            "Transformers map sequences of input vectors (x1,...,xn) to sequences of output\n",
            "vectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\n",
            "former blocks, each of which is a multilayer network made by combining simple\n",
            "linear layers, feedforward networks, and self-attention layers, the key innovation of\n",
            "self-attention\n",
            "transformers. Self-attention allows a network to directly extract and use information\n",
            "from arbitrarily large contexts without the need to pass it through intermediate re-\n",
            "\n",
            "214\n",
            "CHAPTER 10\n",
            "•\n",
            "TRANSFORMERS AND PRETRAINED LANGUAGE MODELS\n",
            "• As the current focus of attention when being compared to all of the other\n",
            "preceding inputs. We’ll refer to this role as a query.\n",
            "query\n",
            "• In its role as a preceding input being compared to the current focus of atten-\n",
            "tion. We’ll refer to this role as a key.\n",
            "key\n",
            "• And ﬁnally, as a value used to compute the output for the current focus of\n",
            "value\n",
            "attention.\n",
            "To capture these three different roles, transformers introduce weight matrices\n",
            "WQ, WK, and WV. These weights will be used to project each input vector xi into\n",
            "a representation of its role as a key, query, or value.\n",
            "qi = WQxi; ki = WKxi; vi = WVxi\n",
            "(10.5)\n",
            "\n",
            "dictates the complexity of model. Both the time and memory requirements in a\n",
            "transformer grow quadratically with the length of the input. It’s necessary, therefore,\n",
            "to set a ﬁxed input length that is long enough to provide sufﬁcient context for the\n",
            "    Question: <pad>  Is  the  Transformers  a  statistical  model?\n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'question': 'Is it a statistical model?',\n",
              " 'chat_history': [HumanMessage(content='Who are you by the way?'),\n",
              "  AIMessage(content='<pad>  I  am  Chaky.\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include`< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.6\\n Suppose  we  didn’t  use  the  end-symbol  .  Train  an  unsmoothed  bigram  grammar  on  the  following  training  corpus  without  using  the  end-symbol:\\n< s>\\n I  do  not  like  green  eggs  and  Sam\\n Using  a  bigram  language  model  with  add-one  smoothing,  what  is  P(Sam  |  am)?  Include{< s>` and` am` in  your  counts  just  like  any  other  token.\\n 3.7\\n Suppose  we  didn’t  use  the  end-symbol  .  Train '),\n",
              "  HumanMessage(content='What is the Transformers?'),\n",
              "  AIMessage(content='<pad>  transformers  are  a  type  of  neural  network  that  are  used  to  map  sequences  of  input  vectors  (x1,...,xn)  to  sequences  of  output  vectors  (y1,...,yn)  of  the  same  length.  They  are  made  up  of  stacks  of  transformer  blocks,  each  of  which  is  a  multilayer  network  made  by  combining  simple  linear  layers,  feedforward  networks,  and  self-attention  layers,  the  key  innovation  of  self-attention  transformers.  Self-attention  allows  a  network  to  directly  extract  and  use  information  from  arbitrarily  large  contexts  without  the  need  to  pass  it  through  intermediate  re-\\n multaneously.  For  example,  distinct  syntactic,  semantic,  and  discourse  relationships  can  hold  between  verbs  and  their  arguments  in ')],\n",
              " 'answer': '<pad> Yes,  transformers  are  a  statistical  model  that  use  probability  to  learn  the  relationships  between  input  and  output  vectors.  They  are  based  on  the  idea  that  the  input  vectors  are  a  sequence  of  probabilities,  and  that  the  output  vectors  are  a  sequence  of  probabilities  that  are  a  product  of  the  input  vectors.  This  allows  the  model  to  learn  the  relationships  between  input  and  output  vectors  by  comparing  the  probabilities  of  the  input  vectors  to  the  probabilities  of  the  output  vectors.\\n',\n",
              " 'source_documents': [Document(page_content='sequence, i.e. the target string with the highest probability. Fig. 10.8 demonstrates\\nthe problem, using a made-up example. Notice that the most probable sequence is\\nok ok </s> (with a probability of .4*.7*1.0), but a greedy search algorithm will fail\\nto ﬁnd it, because it incorrectly chooses yes as the ﬁrst word since it has the highest\\nlocal probability.\\nstart\\nok\\nyes\\n</s>\\nok\\nyes\\n</s>\\nok\\nyes\\n</s>\\n</s>\\n</s>\\n</s>\\n</s>\\nt2\\nt3\\np(t1|start)\\nt1\\np(t2| t1)\\np(t3| t1,t2)\\n.1\\n.5\\n.4\\n.2\\n.4\\n.3\\n.1\\n.2\\n.7\\n1.0\\n1.0\\n1.0\\n1.0\\nFigure 10.8\\nA search tree for generating the target string T = t1,t2,... from the vocabulary\\nV = {yes,ok,<s>}, showing the probability of generating each token from that state. Greedy', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 229, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='formers are not based on recurrent connections (which can be hard to parallelize),\\nwhich means that transformers can be more efﬁcient to implement at scale.\\nTransformers map sequences of input vectors (x1,...,xn) to sequences of output\\nvectors (y1,...,yn) of the same length. Transformers are made up of stacks of trans-\\nformer blocks, each of which is a multilayer network made by combining simple\\nlinear layers, feedforward networks, and self-attention layers, the key innovation of\\nself-attention\\ntransformers. Self-attention allows a network to directly extract and use information\\nfrom arbitrarily large contexts without the need to pass it through intermediate re-', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 219, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='214\\nCHAPTER 10\\n•\\nTRANSFORMERS AND PRETRAINED LANGUAGE MODELS\\n• As the current focus of attention when being compared to all of the other\\npreceding inputs. We’ll refer to this role as a query.\\nquery\\n• In its role as a preceding input being compared to the current focus of atten-\\ntion. We’ll refer to this role as a key.\\nkey\\n• And ﬁnally, as a value used to compute the output for the current focus of\\nvalue\\nattention.\\nTo capture these three different roles, transformers introduce weight matrices\\nWQ, WK, and WV. These weights will be used to project each input vector xi into\\na representation of its role as a key, query, or value.\\nqi = WQxi; ki = WKxi; vi = WVxi\\n(10.5)', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 221, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''}),\n",
              "  Document(page_content='dictates the complexity of model. Both the time and memory requirements in a\\ntransformer grow quadratically with the length of the input. It’s necessary, therefore,\\nto set a ﬁxed input length that is long enough to provide sufﬁcient context for the', metadata={'source': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'file_path': '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf', 'page': 238, 'total_pages': 636, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.21', 'creationDate': \"D:20230107092057-08'00'\", 'modDate': \"D:20230107092057-08'00'\", 'trapped': ''})]}"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_question = \"Is it a statistical model?\"\n",
        "answer = chain({\"question\":prompt_question})\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qysVltcd1dD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLiWgCa7d1dD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a29eb59454941b9944ba065bb9e8c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a14592db94ee48d78d1df159f91a2b8c",
              "IPY_MODEL_84c785c2a39444849e13be49f34ea612",
              "IPY_MODEL_c22744991128444a8b85bc2df50eab3d"
            ],
            "layout": "IPY_MODEL_d132d7e2ba99430597bc3a19572e9a39"
          }
        },
        "a14592db94ee48d78d1df159f91a2b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f985afcdde8443cb4d7ce2adfc60c6e",
            "placeholder": "​",
            "style": "IPY_MODEL_02008f67aeac438a959d6028f214400a",
            "value": "modules.json: 100%"
          }
        },
        "84c785c2a39444849e13be49f34ea612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d0f3e73768459281266caa6c206abf",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e669ed37df974ab291e65b8580bbb3de",
            "value": 349
          }
        },
        "c22744991128444a8b85bc2df50eab3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3ff41ffb67e4dccb601d97b2076dc01",
            "placeholder": "​",
            "style": "IPY_MODEL_1d39d00ed41f4759ab95cdc41f7d726d",
            "value": " 349/349 [00:00&lt;00:00, 43.0kB/s]"
          }
        },
        "d132d7e2ba99430597bc3a19572e9a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f985afcdde8443cb4d7ce2adfc60c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02008f67aeac438a959d6028f214400a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98d0f3e73768459281266caa6c206abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e669ed37df974ab291e65b8580bbb3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3ff41ffb67e4dccb601d97b2076dc01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d39d00ed41f4759ab95cdc41f7d726d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7873f25bf18d4512838da390f4bd9053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dbc15bcde1f443aa3c3e126793cb77a",
              "IPY_MODEL_501e5a75250e4f1c95ebc05fb615b3e8",
              "IPY_MODEL_bc9dec83f60d44e69c9d32a4455ece66"
            ],
            "layout": "IPY_MODEL_304d18c705274411a79e95bb491b5e52"
          }
        },
        "2dbc15bcde1f443aa3c3e126793cb77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c22bc257b045c4b68a0a70c2b3750f",
            "placeholder": "​",
            "style": "IPY_MODEL_46eeb4d5b13b427283693439954f201e",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "501e5a75250e4f1c95ebc05fb615b3e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f9fa454bcab46a8a622fe078dd10206",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6d641f53308440c8b56f6b1202e111c",
            "value": 116
          }
        },
        "bc9dec83f60d44e69c9d32a4455ece66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b26d78c9af44088368aa4ad381438e",
            "placeholder": "​",
            "style": "IPY_MODEL_84ae50655cd74d68ad658823a005a3e5",
            "value": " 116/116 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "304d18c705274411a79e95bb491b5e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c22bc257b045c4b68a0a70c2b3750f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46eeb4d5b13b427283693439954f201e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f9fa454bcab46a8a622fe078dd10206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d641f53308440c8b56f6b1202e111c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77b26d78c9af44088368aa4ad381438e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ae50655cd74d68ad658823a005a3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2807656cb31344dda1ea10f0554f5958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59181b1df9354330b13b3acf7fcb34d8",
              "IPY_MODEL_4a7a5f877e834f4abe7982a4ba6da22c",
              "IPY_MODEL_4ebf1ad73a604171a023e41c03b278b0"
            ],
            "layout": "IPY_MODEL_0a666fb05ea84948b9a8bae8feb004ec"
          }
        },
        "59181b1df9354330b13b3acf7fcb34d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7ab3a4c45814361a6f325a8c52d639e",
            "placeholder": "​",
            "style": "IPY_MODEL_0eb9c9d45c004508a4e063e19bfc6a39",
            "value": "README.md: 100%"
          }
        },
        "4a7a5f877e834f4abe7982a4ba6da22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c54f3b6a87d424ab9382031f75b4dfc",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e70e3a55be14d5e89112d15c01f9ec5",
            "value": 10454
          }
        },
        "4ebf1ad73a604171a023e41c03b278b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d903c9bf14004d3ebb972eabdcab7b32",
            "placeholder": "​",
            "style": "IPY_MODEL_f31bd457bc4645b3af6dfee0367e1333",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 1.43MB/s]"
          }
        },
        "0a666fb05ea84948b9a8bae8feb004ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ab3a4c45814361a6f325a8c52d639e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb9c9d45c004508a4e063e19bfc6a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c54f3b6a87d424ab9382031f75b4dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e70e3a55be14d5e89112d15c01f9ec5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d903c9bf14004d3ebb972eabdcab7b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f31bd457bc4645b3af6dfee0367e1333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95949b82a9bc4da5b3b5aa6c10867d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_708c927435b04113838c258e37baf0f8",
              "IPY_MODEL_8fab9b5bb94645b197bf5119118c082c",
              "IPY_MODEL_1d1b677a7fec427685d97d1c9ff7fb6c"
            ],
            "layout": "IPY_MODEL_171e70e03baa41de8922fdcdd1231973"
          }
        },
        "708c927435b04113838c258e37baf0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5555cae32c96451c98d8c0d207db59d5",
            "placeholder": "​",
            "style": "IPY_MODEL_c42375258df14c80a5540526c74d9857",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "8fab9b5bb94645b197bf5119118c082c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7cc9056f9e64073b544f4d5f1290e42",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_861bed8accb24d59b31d02b619f622e2",
            "value": 53
          }
        },
        "1d1b677a7fec427685d97d1c9ff7fb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d1ef7a54a149dc9270ddeec536c55f",
            "placeholder": "​",
            "style": "IPY_MODEL_4b942049eab34417883c1f1ec4588b03",
            "value": " 53.0/53.0 [00:00&lt;00:00, 6.96kB/s]"
          }
        },
        "171e70e03baa41de8922fdcdd1231973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5555cae32c96451c98d8c0d207db59d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c42375258df14c80a5540526c74d9857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7cc9056f9e64073b544f4d5f1290e42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861bed8accb24d59b31d02b619f622e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98d1ef7a54a149dc9270ddeec536c55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b942049eab34417883c1f1ec4588b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af4faa13f3143f7a0f5f676838f5b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac82c83586a64337996bd9196a12a050",
              "IPY_MODEL_c644688513d3420c802abbe34cebd584",
              "IPY_MODEL_c0e8a6976bcd4e12a4c472398d472a3a"
            ],
            "layout": "IPY_MODEL_4e7d7362188e42fca123b5075797061d"
          }
        },
        "ac82c83586a64337996bd9196a12a050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a78f8d194c0496a9e843e2fdd3a0298",
            "placeholder": "​",
            "style": "IPY_MODEL_e0f96f76eaf44a80a7a25350f30809d9",
            "value": "config.json: 100%"
          }
        },
        "c644688513d3420c802abbe34cebd584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_805134c03ba14653a4feff008d00771a",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d112fcf113f4100ba5c4c37a984618b",
            "value": 612
          }
        },
        "c0e8a6976bcd4e12a4c472398d472a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb79fce4fae74b8285eef333c5f7bc77",
            "placeholder": "​",
            "style": "IPY_MODEL_de619b94fab142169b70ff74d16854b9",
            "value": " 612/612 [00:00&lt;00:00, 86.8kB/s]"
          }
        },
        "4e7d7362188e42fca123b5075797061d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a78f8d194c0496a9e843e2fdd3a0298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0f96f76eaf44a80a7a25350f30809d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "805134c03ba14653a4feff008d00771a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d112fcf113f4100ba5c4c37a984618b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb79fce4fae74b8285eef333c5f7bc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de619b94fab142169b70ff74d16854b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab0b78f473154a5c87d8ca07c7f0e287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5c97e53ca4a4e28b53dd6f13f8bebaa",
              "IPY_MODEL_33edc46ed7ea4db08ff98e7e315511a7",
              "IPY_MODEL_d8feceda4f6845ef8a0c75ed1ead81fb"
            ],
            "layout": "IPY_MODEL_481434e222a64c09a9581debf32a6f67"
          }
        },
        "b5c97e53ca4a4e28b53dd6f13f8bebaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a128af895b764911af827161f00f031a",
            "placeholder": "​",
            "style": "IPY_MODEL_4b480e7015744449aea6139ecd538887",
            "value": "model.safetensors: 100%"
          }
        },
        "33edc46ed7ea4db08ff98e7e315511a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f431ae3fab466abbd8f4d7d805f334",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba395d8269644cfdb126925d53176044",
            "value": 90868376
          }
        },
        "d8feceda4f6845ef8a0c75ed1ead81fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6295f7a556f94748826e00abc5841150",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5bc290b7b8443591f961d69055fcb3",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 194MB/s]"
          }
        },
        "481434e222a64c09a9581debf32a6f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a128af895b764911af827161f00f031a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b480e7015744449aea6139ecd538887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3f431ae3fab466abbd8f4d7d805f334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba395d8269644cfdb126925d53176044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6295f7a556f94748826e00abc5841150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5bc290b7b8443591f961d69055fcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84a7bf4bf3534fc8857c352e727330b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66cb3715035641f6880c42a038defa6b",
              "IPY_MODEL_7e1e0fcc1f0e4450910b2fa257723a16",
              "IPY_MODEL_498c2800fcf14e059edb334e76c124aa"
            ],
            "layout": "IPY_MODEL_1231873fe28b4db69b87decbf9897fdb"
          }
        },
        "66cb3715035641f6880c42a038defa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a73d0ba8b34b3f8de26b979bbcff1d",
            "placeholder": "​",
            "style": "IPY_MODEL_ac91c2521a1245ed82e2c15b82e8328e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7e1e0fcc1f0e4450910b2fa257723a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1d9e384eb94bd9949199626067f2cf",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a299a4b4d5444c6a11e5a5e48c2b48a",
            "value": 350
          }
        },
        "498c2800fcf14e059edb334e76c124aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7580c03d32b340579e141f56bde9fe61",
            "placeholder": "​",
            "style": "IPY_MODEL_58ac40b3345343ac91e756a76148e0b6",
            "value": " 350/350 [00:00&lt;00:00, 46.1kB/s]"
          }
        },
        "1231873fe28b4db69b87decbf9897fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a73d0ba8b34b3f8de26b979bbcff1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac91c2521a1245ed82e2c15b82e8328e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1d9e384eb94bd9949199626067f2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a299a4b4d5444c6a11e5a5e48c2b48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7580c03d32b340579e141f56bde9fe61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ac40b3345343ac91e756a76148e0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6de11dfa87ee4de287dab727b6733477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51c215e80c8a470085aa16be4591ffff",
              "IPY_MODEL_1fd09386009e44c19b4d51ad8f2dba1e",
              "IPY_MODEL_cd084e7bb2fa428492e63b113552d11e"
            ],
            "layout": "IPY_MODEL_3e20b33f66b6424382fc5e34524a3d0d"
          }
        },
        "51c215e80c8a470085aa16be4591ffff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a96d7c53ba3c40be99317dda013bd486",
            "placeholder": "​",
            "style": "IPY_MODEL_b6043692908f4293a8e7f23c02cf043a",
            "value": "vocab.txt: 100%"
          }
        },
        "1fd09386009e44c19b4d51ad8f2dba1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc79201cb33b460f89a7f864c9c6e36e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_716a5939a0954bb3b9acf24c1a17c8c8",
            "value": 231508
          }
        },
        "cd084e7bb2fa428492e63b113552d11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b68075b0bc4a46018af40890112e4a08",
            "placeholder": "​",
            "style": "IPY_MODEL_a2a78fc59f3942ae97686bc517f3c6d9",
            "value": " 232k/232k [00:00&lt;00:00, 6.61MB/s]"
          }
        },
        "3e20b33f66b6424382fc5e34524a3d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a96d7c53ba3c40be99317dda013bd486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6043692908f4293a8e7f23c02cf043a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc79201cb33b460f89a7f864c9c6e36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "716a5939a0954bb3b9acf24c1a17c8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b68075b0bc4a46018af40890112e4a08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a78fc59f3942ae97686bc517f3c6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68c3d88fa3b345009a6d594f3fa4db24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2843989dfb4442cad13cb068f5d0c8b",
              "IPY_MODEL_23cabbef947c428095b03827e56e8062",
              "IPY_MODEL_1162fd57e9254b7dac10e6ad8bfc8e22"
            ],
            "layout": "IPY_MODEL_d6c0f0f4ce5143cea81b3986f8525d94"
          }
        },
        "e2843989dfb4442cad13cb068f5d0c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e136238969a40b28fb68023a7cefd3c",
            "placeholder": "​",
            "style": "IPY_MODEL_ce07010d2595417ebbcef94859341765",
            "value": "tokenizer.json: 100%"
          }
        },
        "23cabbef947c428095b03827e56e8062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b608d586a3c24ff0b3f7bf907b605245",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7443a33abe924a53a895f224fc324c58",
            "value": 466247
          }
        },
        "1162fd57e9254b7dac10e6ad8bfc8e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b147cd74ecb45ac9291c0b0e8c5f6cc",
            "placeholder": "​",
            "style": "IPY_MODEL_54586540a25d4b01b2186d2e91600132",
            "value": " 466k/466k [00:00&lt;00:00, 14.1MB/s]"
          }
        },
        "d6c0f0f4ce5143cea81b3986f8525d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e136238969a40b28fb68023a7cefd3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce07010d2595417ebbcef94859341765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b608d586a3c24ff0b3f7bf907b605245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7443a33abe924a53a895f224fc324c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b147cd74ecb45ac9291c0b0e8c5f6cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54586540a25d4b01b2186d2e91600132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3711f39099c34abb96d00b06b1ae0b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7de613efa0c1469d9cc1469d3117e72d",
              "IPY_MODEL_d5d5839835a34375b8c0c22006947668",
              "IPY_MODEL_5b194de0b0d64565b713c256038dbac4"
            ],
            "layout": "IPY_MODEL_9c64d349d8744ed3ace77b6ac10a6abc"
          }
        },
        "7de613efa0c1469d9cc1469d3117e72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80ef30acb7c64e15830242bb90b00428",
            "placeholder": "​",
            "style": "IPY_MODEL_049f159746d44a999b42059813f8081a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d5d5839835a34375b8c0c22006947668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91d0851b1e84cb58b8cd5145b8a8d69",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7c9120e208046c897aab24c4b03163a",
            "value": 112
          }
        },
        "5b194de0b0d64565b713c256038dbac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10147b15dd474fdbab4bdbbe31a74c3b",
            "placeholder": "​",
            "style": "IPY_MODEL_d4eca018c3674380bfeb98c444442136",
            "value": " 112/112 [00:00&lt;00:00, 14.5kB/s]"
          }
        },
        "9c64d349d8744ed3ace77b6ac10a6abc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ef30acb7c64e15830242bb90b00428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049f159746d44a999b42059813f8081a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a91d0851b1e84cb58b8cd5145b8a8d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7c9120e208046c897aab24c4b03163a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10147b15dd474fdbab4bdbbe31a74c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4eca018c3674380bfeb98c444442136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2ee7c0e955d439e8ad68e28be9f40d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdfdade1a27b47169da39e592546351c",
              "IPY_MODEL_88a85cd8b0244123b971f31aee8e5eb8",
              "IPY_MODEL_c7b70a10767a45e1b360b9325af11165"
            ],
            "layout": "IPY_MODEL_3c8af24f3d65462a8ca90b3f94bc1013"
          }
        },
        "cdfdade1a27b47169da39e592546351c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de5bda4789c34fb7a4fdba9036923236",
            "placeholder": "​",
            "style": "IPY_MODEL_514d16c8a42c40e69b4ce59f399fd5ec",
            "value": "config.json: 100%"
          }
        },
        "88a85cd8b0244123b971f31aee8e5eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50203dede23b45d69bf8dc1680f49aa2",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8c9f625daff48b7ae85a33b9f73f892",
            "value": 190
          }
        },
        "c7b70a10767a45e1b360b9325af11165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aaba50955b03423483b29929d6c12cab",
            "placeholder": "​",
            "style": "IPY_MODEL_244b8408b5934bc39cdcf650bb24c532",
            "value": " 190/190 [00:00&lt;00:00, 23.7kB/s]"
          }
        },
        "3c8af24f3d65462a8ca90b3f94bc1013": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de5bda4789c34fb7a4fdba9036923236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514d16c8a42c40e69b4ce59f399fd5ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50203dede23b45d69bf8dc1680f49aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c9f625daff48b7ae85a33b9f73f892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaba50955b03423483b29929d6c12cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "244b8408b5934bc39cdcf650bb24c532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}