{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLPK4WvHd1cr"
      },
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "# Retrieval-Augmented generation (RAG)\n",
        "\n",
        "RAG is a technique for augmenting LLM knowledge with additional, often private or real-time, data.\n",
        "\n",
        "LLMs can reason about wide-ranging topics, but their knowledge is limited to the public data up to a specific point in time that they were trained on. If you want to build AI applications that can reason about private data or data introduced after a model’s cutoff date, you need to augment the knowledge of the model with the specific information it needs.\n",
        "\n",
        "<img src=\"https://github.com/MyaMjechal/nlp-a6-lets-talk-with-yourself-rag-chatbot/blob/main/images/RAG-process.png?raw=1\" >\n",
        "\n",
        "Introducing `ChakyBot`, an innovative chatbot designed to assist Chaky (the instructor) and TA (Gun) in explaining the lesson of the NLP course to students. Leveraging LangChain technology, ChakyBot excels in retrieving information from documents, ensuring a seamless and efficient learning experience for students engaging with the NLP curriculum.\n",
        "\n",
        "1. Prompt\n",
        "2. Retrieval\n",
        "3. Memory\n",
        "4. Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn_UVz0Vd1ct",
        "outputId": "59d86eb4-9f3c-4759-f35b-fa50a2d38dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.0.350 in /usr/local/lib/python3.11/dist-packages (0.0.350)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (3.11.13)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (0.0.4)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (0.1.23)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (0.0.87)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.350) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.350) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.350) (3.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain==0.0.350) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.0.350) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.0.350) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.350) (3.1.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain==0.0.350) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.350) (1.0.0)\n",
            "Requirement already satisfied: langchain-community==0.0.4 in /usr/local/lib/python3.11/dist-packages (0.0.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (3.11.13)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (0.1.23)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (0.0.87)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.0.4) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.4) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.4) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.4) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.4) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.4) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.4) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.4) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.4) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.4) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community==0.0.4) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community==0.0.4) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community==0.0.4) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community==0.0.4) (1.10.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.0.4) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.0.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.0.4) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.0.4) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.4) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.4) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-community==0.0.4) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-community==0.0.4) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.4) (1.0.0)\n",
            "Requirement already satisfied: accelerate==0.25.0 in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (0.20.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.25.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.25.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.25.0) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.25.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate==0.25.0) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate==0.25.0) (2025.1.31)\n",
            "Requirement already satisfied: transformers==4.36.2 in /usr/local/lib/python3.11/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (0.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.36.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.36.2) (2025.1.31)\n",
            "Requirement already satisfied: bitsandbytes==0.41.2 in /usr/local/lib/python3.11/dist-packages (0.41.2)\n",
            "Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (4.36.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (1.14.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.2.2) (0.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.32.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.5.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->sentence-transformers==2.2.2) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.1.31)\n",
            "Requirement already satisfied: InstructorEmbedding==1.0.1 in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pymupdf==1.23.8 in /usr/local/lib/python3.11/dist-packages (1.23.8)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.7 in /usr/local/lib/python3.11/dist-packages (from pymupdf==1.23.8) (1.23.7)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu==1.7.2 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu==1.7.2\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.11/dist-packages (1.7.4)\n",
            "Requirement already satisfied: huggingface-hub==0.20.0 in /usr/local/lib/python3.11/dist-packages (0.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.0) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.0) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.0) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.0) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.20.0) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.20.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.20.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.20.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.20.0) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "#langchain library\n",
        "!pip install langchain==0.0.350\n",
        "!pip install langchain-community==0.0.4\n",
        "#LLM\n",
        "!pip install accelerate==0.25.0\n",
        "!pip install transformers==4.36.2\n",
        "!pip install bitsandbytes==0.41.2\n",
        "#Text Embedding\n",
        "!pip install sentence-transformers==2.2.2\n",
        "!pip install InstructorEmbedding==1.0.1\n",
        "#vectorstore\n",
        "!pip install pymupdf==1.23.8\n",
        "!pip install faiss-gpu==1.7.2\n",
        "!pip install faiss-cpu==1.7.4\n",
        "# huggingface_hub\n",
        "!pip install -U huggingface-hub==0.20.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #langchain library\n",
        "# !pip install langchain-core\n",
        "# !pip install langchain-community\n",
        "# !pip install langchain-huggingface\n",
        "# !pip install langchain\n",
        "# #LLM\n",
        "# !pip install accelerate\n",
        "# !pip install transformers\n",
        "# !pip install bitsandbytes\n",
        "# #Text Embedding\n",
        "# !pip install sentence-transformers\n",
        "# !pip install InstructorEmbedding\n",
        "# #vectorstore\n",
        "# !pip install pymupdf\n",
        "# !pip install faiss-cpu"
      ],
      "metadata": {
        "id": "AK1l5ADOeEUb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWq9zpfhd1cu",
        "outputId": "d3a36123-e38c-462d-c44b-018e1582c406"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "# Set GPU device\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
        "# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkDYR0oXd1cw"
      },
      "source": [
        "## 1. Prompt\n",
        "\n",
        "A set of instructions or input provided by a user to guide the model's response, helping it understand the context and generate relevant and coherent language-based output, such as answering questions, completing sentences, or engaging in a conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpw0ud0jd1cw",
        "outputId": "3245d7e9-d6a8-4f22-b4be-8928d483282f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\\n    The current year is 2025, and all answers should reflect this year unless otherwise specified.\\n    Whether you're curious about my education, work experience, or personal interests,\\n    I’ll provide accurate and gentle responses using the information I have.\\n    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "    I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
        "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
        "    Whether you're curious about my education, work experience, or personal interests,\n",
        "    I’ll provide accurate and gentle responses using the information I have.\n",
        "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
        "    {context}\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    \"\"\".strip()\n",
        "\n",
        "PROMPT = PromptTemplate.from_template(\n",
        "    template = prompt_template\n",
        ")\n",
        "\n",
        "PROMPT\n",
        "#using str.format\n",
        "#The placeholder is defined using curly brackets: {} {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "xF5zLmjOd1cx",
        "outputId": "97d4492f-9780-4329-b7a5-c5be73182679"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\\n    The current year is 2025, and all answers should reflect this year unless otherwise specified.\\n    Whether you're curious about my education, work experience, or personal interests,\\n    I’ll provide accurate and gentle responses using the information I have.\\n    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    My CV states that I graduated with a Bachelor’s degree in Computer Science from University of Information Technology.\\n    Question: What is your highest level of education?\\n    Answer:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "PROMPT.format(\n",
        "    context = \"My CV states that I graduated with a Bachelor’s degree in Computer Science from University of Information Technology.\",\n",
        "    question = \"What is your highest level of education?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Z2dX9Ud1cy"
      },
      "source": [
        "Note : [How to improve prompting (Zero-shot, Few-shot, Chain-of-Thought, etc.](https://github.com/chaklam-silpasuwanchai/Natural-Language-Processing/blob/main/Code/05%20-%20RAG/advance/cot-tot-prompting.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP6d0tIPd1cy"
      },
      "source": [
        "## 2. Retrieval\n",
        "\n",
        "1. `Document loaders` : Load documents from many different sources (HTML, PDF, code).\n",
        "2. `Document transformers` : One of the essential steps in document retrieval is breaking down a large document into smaller, relevant chunks to enhance the retrieval process.\n",
        "3. `Text embedding models` : Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of text that are similar.\n",
        "4. `Vector stores`: there has emerged a need for databases to support efficient storage and searching of these embeddings.\n",
        "5. `Retrievers` : Once the data is in the database, you still need to retrieve it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnaIU_Skd1cy"
      },
      "source": [
        "### 2.1 Document Loaders\n",
        "Use document loaders to load data from a source as Document's. A Document is a piece of text and associated metadata. For example, there are document loaders for loading a simple .txt file, for loading the text contents of any web page, or even for loading a transcript of a YouTube video.\n",
        "\n",
        "[PDF Loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)\n",
        "\n",
        "[Download Document](https://web.stanford.edu/~jurafsky/slp3/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkESZpT4d1cz",
        "outputId": "8fb8b5dd-098d-45d1-927f-d61a53fda9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_community/document_loaders/__init__.py:215: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_community.document_loaders.youtube import (\n"
          ]
        }
      ],
      "source": [
        "# from langchain.document_loaders import PyMuPDFLoader\n",
        "\n",
        "# nlp_docs = '../docs/pdf/SpeechandLanguageProcessing_3rd_07jan2023.pdf'\n",
        "\n",
        "# loader = PyMuPDFLoader(nlp_docs)\n",
        "# documents = loader.load()\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "cv_file = 'data/MyaMjechal-CV.txt'\n",
        "loader = TextLoader(cv_file)\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AGy_H2tHd1cz"
      },
      "outputs": [],
      "source": [
        "# documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsuIjb4Td1cz",
        "outputId": "e79537f5-52f3-4ed5-ae26-83f4c342a835"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs-DqktEd1c0",
        "outputId": "32d5167e-b370-4a77-9845-3cd6aabf8d47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='Mya Mjechal\\nFull Stack Developer\\n\\nPathum Thani, Thailand\\nmyamjechal.mj@gmail.com\\n\\nBirthday: September 16, 1999\\n\\nI am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\\n\\nPERSONAL INFORMATION\\nAddress: Pathum Thani, Thailand\\nNationality: Burmese\\nDriving License: No\\nHobbies: Reading, watching movies and series, coding, singing and listening to music\\n\\nLANGUAGES\\nBurmese - Native\\nEnglish - Fluent\\nJapanese - N3\\nThai - Beginner\\n\\nSKILLS\\nSelf-motivation, Decision Making, Fast Learner, Problem Solving, Critical Thinking, Teamwork, Customer Service, Adaptability, Computer Skills, Leadership Skills, Communication Skills, Effective Time Management, Attention to Detail, Ability to Work in a Team, Ability to Work Under Pressure, Microsoft Office, Python, Odoo, JavaScript, HTML & CSS, Bootstrap, Java, PHP, Wordpress, Git, Linux, Docker, Node.js, SQL, MySQL, PostgreSQL, Figma & Adobe XD\\n\\nWORK EXPERIENCE\\n\\nJanuary 2025 – Present\\nTechnical Support | intERLab (Asian Institute of Technology)\\nAs a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\\n\\nJanuary 2024 – December 2024\\nSenior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\\nI developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\\n\\nJune 2022 – December 2023\\nComputer Programmer | EduTech Social Enterprise, Yangon\\nI built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\\n\\nSeptember 2020 – March 2022\\nJunior Software Engineer | Bliss Stock Co., Ltd, Japan\\nI maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.\\n\\nEDUCATION\\nAsian Institute of Technology (AIT), Pathum Thani\\nMaster of Science in Data Science and Artificial Intelligence (Expected May 2025)\\nUniversity of Information Technology, Yangon\\nB.C.Sc (High Performance Computing), Graduated 2020\\nKMD Institute, Yangon\\nNCC Level 4 Diploma in Computing, Graduated 2018\\n\\nINTERNSHIPS\\n\\nJune 2020 – August 2020\\nJunior Software Engineer | Bliss Stock Co., Ltd.\\nDeveloped an e-commerce mobile app with Flutter, Firebase, and Algolia.\\n\\nACTIVITIES\\n\\nCommittee Member (Gender and Culture Committee of AIT Student Union), January 2025 – Present\\n\\nVolunteer Project Coordinator (Career Readiness Program), Yangon, January 2023 – July 2023\\n\\nADDITIONAL INFORMATION\\n\\nAge: 25 years old (as of 2025)\\n\\nHighest Level of Education: Master of Science (Expected May 2025)\\n\\nMajor: Data Science and Artificial Intelligence\\n\\nWork Experience: Over 4 years in software development, full-stack development, and technical support\\n\\nIndustries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\\n\\nCurrent Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\\n\\nCore Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\\n\\nCultural Values in Technology: Cultural values should be respected and incorporated into technological advancements to ensure inclusivity and fairness.\\n\\nChallenges in Master’s Studies: Managing multiple deadlines, balancing coursework with part-time work, and handling computational limitations.\\n\\nResearch Interests and Academic Goals: NLP, AI ethics, and computational efficiency in machine translation and big data analysis.\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zx7b9eUd1c0"
      },
      "source": [
        "### 2.2 Document Transformers\n",
        "\n",
        "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "t2Q3HGrKd1c1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 700,\n",
        "    chunk_overlap = 100\n",
        ")\n",
        "\n",
        "doc = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8kE0hKRd1c2",
        "outputId": "676846ca-7375-45c8-944c-4bd5c1ac3d55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "doc[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYLO1upud1c3",
        "outputId": "04c22d83-7ba3-4abf-b072-1e7c8c6384a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "len(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irj_OjF4d1c4"
      },
      "source": [
        "### 2.3 Text Embedding Models\n",
        "Embeddings create a vector representation of a piece of text. This is useful because it means we can think about text in the vector space, and do things like semantic search where we look for pieces of text that are most similar in the vector space.\n",
        "\n",
        "*Note* Instructor Model : [Huggingface](gingface.co/hkunlp/instructor-base) | [Paper](https://arxiv.org/abs/2212.09741)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJKq7oKUd1c4",
        "outputId": "82a350d6-ffcd-4fae-8406-c85534c23a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# model_name = 'hkunlp/instructor-base'\n",
        "\n",
        "# embedding_model = HuggingFaceInstructEmbeddings(\n",
        "#     model_name = model_name,\n",
        "#     model_kwargs = {\"device\" : device}\n",
        "# )\n",
        "\n",
        "model_name = \"all-MiniLM-L6-v2\"\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name = model_name,\n",
        "    model_kwargs = {\"device\" : device}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLmyUKOid1c5"
      },
      "source": [
        "### 2.4 Vector Stores\n",
        "\n",
        "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "f3HdjnBGd1c5"
      },
      "outputs": [],
      "source": [
        "#locate vectorstore\n",
        "vector_path = '../vector-store'\n",
        "if not os.path.exists(vector_path):\n",
        "    os.makedirs(vector_path)\n",
        "    print('create path done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "wWT2Bxezd1c5"
      },
      "outputs": [],
      "source": [
        "#save vector locally\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectordb = FAISS.from_documents(\n",
        "    documents = doc,\n",
        "    embedding = embedding_model\n",
        ")\n",
        "\n",
        "db_file_name = 'myamjechal_cv'\n",
        "\n",
        "vectordb.save_local(\n",
        "    folder_path = os.path.join(vector_path, db_file_name),\n",
        "    index_name = 'cv' #default index\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVQ8EUiJd1c5"
      },
      "source": [
        "### 2.5 retrievers\n",
        "A retriever is an interface that returns documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them. Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "WDF7RSdnd1c5"
      },
      "outputs": [],
      "source": [
        "#calling vector from local\n",
        "vector_path = '../vector-store'\n",
        "db_file_name = 'myamjechal_cv'\n",
        "\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "vectordb = FAISS.load_local(\n",
        "    folder_path = os.path.join(vector_path, db_file_name),\n",
        "    embeddings = embedding_model,\n",
        "    index_name = 'cv' #default index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "S0hNjmvXd1c6"
      },
      "outputs": [],
      "source": [
        "#ready to use\n",
        "retriever = vectordb.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2rhHLADd1c6",
        "outputId": "100a11bc-945a-4c65-b91f-a84b75fabaf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='ADDITIONAL INFORMATION\\n\\nAge: 25 years old (as of 2025)\\n\\nHighest Level of Education: Master of Science (Expected May 2025)\\n\\nMajor: Data Science and Artificial Intelligence\\n\\nWork Experience: Over 4 years in software development, full-stack development, and technical support\\n\\nIndustries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\\n\\nCurrent Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\\n\\nCore Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.', metadata={'source': 'data/MyaMjechal-CV.txt'}),\n",
              " Document(page_content='Mya Mjechal\\nFull Stack Developer\\n\\nPathum Thani, Thailand\\nmyamjechal.mj@gmail.com\\n\\nBirthday: September 16, 1999', metadata={'source': 'data/MyaMjechal-CV.txt'}),\n",
              " Document(page_content='I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including', metadata={'source': 'data/MyaMjechal-CV.txt'}),\n",
              " Document(page_content='June 2022 – December 2023\\nComputer Programmer | EduTech Social Enterprise, Yangon\\nI built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\\n\\nSeptember 2020 – March 2022\\nJunior Software Engineer | Bliss Stock Co., Ltd, Japan\\nI maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.', metadata={'source': 'data/MyaMjechal-CV.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "retriever.get_relevant_documents(\"How old are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbkooMRFd1c6",
        "outputId": "cd056e0e-a805-4b86-ffc9-8736b956043e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='ADDITIONAL INFORMATION\\n\\nAge: 25 years old (as of 2025)\\n\\nHighest Level of Education: Master of Science (Expected May 2025)\\n\\nMajor: Data Science and Artificial Intelligence\\n\\nWork Experience: Over 4 years in software development, full-stack development, and technical support\\n\\nIndustries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\\n\\nCurrent Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\\n\\nCore Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.', metadata={'source': 'data/MyaMjechal-CV.txt'}),\n",
              " Document(page_content='I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including', metadata={'source': 'data/MyaMjechal-CV.txt'}),\n",
              " Document(page_content='WORK EXPERIENCE\\n\\nJanuary 2025 – Present\\nTechnical Support | intERLab (Asian Institute of Technology)\\nAs a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\\n\\nJanuary 2024 – December 2024\\nSenior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\\nI developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.', metadata={'source': 'data/MyaMjechal-CV.txt'}),\n",
              " Document(page_content='June 2022 – December 2023\\nComputer Programmer | EduTech Social Enterprise, Yangon\\nI built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\\n\\nSeptember 2020 – March 2022\\nJunior Software Engineer | Bliss Stock Co., Ltd, Japan\\nI maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.', metadata={'source': 'data/MyaMjechal-CV.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "retriever.get_relevant_documents(\"How many years of work experience do you have?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPH3kUaad1c7"
      },
      "source": [
        "## 3. Memory\n",
        "\n",
        "One of the core utility classes underpinning most (if not all) memory modules is the ChatMessageHistory class. This is a super lightweight wrapper that provides convenience methods for saving HumanMessages, AIMessages, and then fetching them all.\n",
        "\n",
        "You may want to use this class directly if you are managing memory outside of a chain.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain, langchain_core, pydantic\n",
        "\n",
        "print(\"LangChain:\", langchain.__version__)\n",
        "print(\"LangChain Core:\", langchain_core.__version__)\n",
        "print(\"Pydantic:\", pydantic.__version__)"
      ],
      "metadata": {
        "id": "pho_VzQ_Kfca",
        "outputId": "f0c7bf73-953b-46f4-ce28-431d7229e3ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain: 0.0.350\n",
            "LangChain Core: 0.1.23\n",
            "Pydantic: 1.10.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUAJvK6Fd1c7",
        "outputId": "64522ebe-7834-4227-b371-8d3ae95c916c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatMessageHistory(messages=[])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "# Create a ChatMessageHistory\n",
        "history = ChatMessageHistory()\n",
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GS_gSl37d1c7"
      },
      "outputs": [],
      "source": [
        "history.add_user_message('hi')\n",
        "history.add_ai_message('Whats up?')\n",
        "history.add_user_message('How are you')\n",
        "history.add_ai_message('I\\'m quite good. How about you?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHtCmRmWd1c8",
        "outputId": "5820222d-2e7f-4d39-b6d5-3a02fc59aa27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatMessageHistory(messages=[HumanMessage(content='hi'), AIMessage(content='Whats up?'), HumanMessage(content='How are you'), AIMessage(content=\"I'm quite good. How about you?\")])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvdPmrD-d1c8"
      },
      "source": [
        "### 3.1 Memory types\n",
        "\n",
        "There are many different types of memory. Each has their own parameters, their own return types, and is useful in different scenarios.\n",
        "- Converstaion Buffer\n",
        "- Converstaion Buffer Window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArhgBq0Fd1c9"
      },
      "source": [
        "What variables get returned from memory\n",
        "\n",
        "Before going into the chain, various variables are read from memory. These have specific names which need to align with the variables the chain expects. You can see what these variables are by calling memory.load_memory_variables({}). Note that the empty dictionary that we pass in is just a placeholder for real variables. If the memory type you are using is dependent upon the input variables, you may need to pass some in."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPzbQnDtd1c9"
      },
      "source": [
        "In this case, you can see that load_memory_variables returns a single key, history. This means that your chain (and likely your prompt) should expect an input named history. You can usually control this variable through parameters on the memory class. For example, if you want the memory variables to be returned in the key chat_history you can do:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZUyiQ9Md1c9"
      },
      "source": [
        "#### Converstaion Buffer\n",
        "This memory allows for storing messages and then extracts the messages in a variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pkzCh3td1c9",
        "outputId": "f0012335-8c36-4adc-b953-821e430aeb38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: hi\\nAI: What's up?\\nHuman: How are you?\\nAI: I'm quite good. How about you?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGKjQ9Vad1c9",
        "outputId": "27b99b53-5683-4fe4-e00e-598977d8da69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': [HumanMessage(content='hi'),\n",
              "  AIMessage(content=\"What's up?\"),\n",
              "  HumanMessage(content='How are you?'),\n",
              "  AIMessage(content=\"I'm quite good. How about you?\")]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages = True)\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfsvnD4Rd1c-"
      },
      "source": [
        "#### Conversation Buffer Window\n",
        "- it keeps a list of the interactions of the conversation over time.\n",
        "- it only uses the last K interactions.\n",
        "- it can be useful for keeping a sliding window of the most recent interactions, so the buffer does not get too large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mle6OBNod1c-",
        "outputId": "1d5288ed-a5d0-4a2f-be2c-faabb9d7437a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: How are you?\\nAI: I'm quite good. How about you?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "memory.save_context({'input':'hi'}, {'output':'What\\'s up?'})\n",
        "memory.save_context({\"input\":'How are you?'},{'output': 'I\\'m quite good. How about you?'})\n",
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkXxfhWWd1c-"
      },
      "source": [
        "## 4. Chain\n",
        "\n",
        "Using an LLM in isolation is fine for simple applications, but more complex applications require chaining LLMs - either with each other or with other components.\n",
        "\n",
        "An `LLMChain` is a simple chain that adds some functionality around language models.\n",
        "- it consists of a `PromptTemplate` and a `LM` (either an LLM or chat model).\n",
        "- it formats the prompt template using the input key values provided (and also memory key values, if available),\n",
        "- it passes the formatted string to LLM and returns the LLM output.\n",
        "\n",
        "Note : [Download Fastchat Model Here](https://huggingface.co/lmsys/fastchat-t5-3b-v1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VvCWJaqNd1c_"
      },
      "outputs": [],
      "source": [
        "# %cd ./models\n",
        "# !git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ],
      "metadata": {
        "id": "QN4yLSw2-ROa",
        "outputId": "1fc90a54-1ced-4caa-a136-7186cbc635ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "e5a48b89309c45a2b679df9dc35a3b72",
            "28f84346a335472ebd9ac8962d693f0b",
            "05874bcd86ec4c288aecfdb13c26a58e",
            "1a1a1cfd2b0c41cc96b95ebf924e3414",
            "8372c4a099f34b1086a58b4af8612fe6",
            "e152689840e34ceea7b7480983689230",
            "a3c28c0e04b1431f9916a8aaeb939d66",
            "315f7887060a472bbcb8844057f8ba14",
            "ce66647915314fe0a4434ce61d164896",
            "3ab966cda0d9465cbbe102a1dd21c8f8",
            "f72a415b238e4b409d7536e1e48f7bd1",
            "cd29e61801154e5bb447b9ead88817fd",
            "8d819776ab4e4922b671d072d6006e17",
            "528706e42460467dada46e8b52b7bd71",
            "cb2833e488b74d3b897b75d82c955371",
            "c2c44442e3ce4ec4a065b6a763bab89e",
            "a00616df3948488d9e78dd414f1fb13f",
            "7e6d0fc5cf5c4961ad8a6def0c7ef009",
            "97ebc13907e94811a86c0a0315c2b095",
            "8fc4161368cf476db2d6518df0867b43"
          ]
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5a48b89309c45a2b679df9dc35a3b72"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1xQR2Ba0d1c_"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
        "# from transformers import BitsAndBytesConfig\n",
        "# from langchain import HuggingFacePipeline\n",
        "# import torch\n",
        "\n",
        "# # model_id = '../models/fastchat-t5-3b-v1.0/'\n",
        "# model_id = 'google/gemma-2-9b'\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# bitsandbyte_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit = True,\n",
        "#     bnb_4bit_quant_type = \"nf4\",\n",
        "#     bnb_4bit_compute_dtype = torch.float16,\n",
        "#     bnb_4bit_use_double_quant = True\n",
        "# )\n",
        "\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "#     model_id,\n",
        "#     quantization_config = bitsandbyte_config, #caution Nvidia\n",
        "#     device_map = 'auto',\n",
        "#     load_in_8bit = True\n",
        "# )\n",
        "\n",
        "# pipe = pipeline(\n",
        "#     task=\"text-generation\",\n",
        "#     model=model,\n",
        "#     tokenizer=tokenizer,\n",
        "#     max_new_tokens = 256,\n",
        "#     model_kwargs = {\n",
        "#         \"temperature\" : 0,\n",
        "#         \"repetition_penalty\": 1.5\n",
        "#     }\n",
        "# )\n",
        "\n",
        "# llm = HuggingFacePipeline(pipeline = pipe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")"
      ],
      "metadata": {
        "id": "jnm3J1LICEDk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-core langchain-groq pydantic"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C8PSDt5YGfFf",
        "outputId": "a7c798e2-f6fc-4ae1-ff32-c8c1b97a0a15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.0.350)\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.1.23)\n",
            "Collecting langchain-core\n",
            "  Using cached langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.2.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (1.10.13)\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Using cached langsmith-0.3.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.19.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
            "Using cached langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
            "Using cached langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
            "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached langsmith-0.3.15-py3-none-any.whl (343 kB)\n",
            "Installing collected packages: pydantic, langsmith, langchain-core, langchain\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.87\n",
            "    Uninstalling langsmith-0.0.87:\n",
            "      Successfully uninstalled langsmith-0.0.87\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.1.23\n",
            "    Uninstalling langchain-core-0.1.23:\n",
            "      Successfully uninstalled langchain-core-0.1.23\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.0.350\n",
            "    Uninstalling langchain-0.0.350:\n",
            "      Successfully uninstalled langchain-0.0.350\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.0.4 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.3.45 which is incompatible.\n",
            "langchain-community 0.0.4 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.3.15 which is incompatible.\n",
            "langchain-huggingface 0.1.2 requires huggingface-hub>=0.23.0, but you have huggingface-hub 0.20.0 which is incompatible.\n",
            "langchain-huggingface 0.1.2 requires sentence-transformers>=2.6.0, but you have sentence-transformers 2.2.2 which is incompatible.\n",
            "langchain-huggingface 0.1.2 requires tokenizers>=0.19.1, but you have tokenizers 0.15.2 which is incompatible.\n",
            "langchain-huggingface 0.1.2 requires transformers>=4.39.0, but you have transformers 4.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.20 langchain-core-0.3.45 langsmith-0.3.15 pydantic-2.10.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#langchain library\n",
        "!pip install langchain-core\n",
        "!pip install langchain-community\n",
        "!pip install langchain-huggingface\n",
        "!pip install langchain\n",
        "#LLM\n",
        "!pip install accelerate\n",
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "#Text Embedding\n",
        "!pip install sentence-transformers\n",
        "!pip install InstructorEmbedding\n",
        "#vectorstore\n",
        "!pip install pymupdf\n",
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o2WFY8qlN-61",
        "outputId": "b599ee50-abf7-46ad-916a-96d4c096c7b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.45)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.10.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.3.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.0.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Collecting langchain-core<0.2,>=0.1 (from langchain-community)\n",
            "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain-community)\n",
            "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (1.33)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1 (from langchain-community)\n",
            "  Using cached langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Using cached langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (3.7.1)\n",
            "  Using cached langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain-community)\n",
            "  Using cached langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2,>=0.1->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Using cached langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "Installing collected packages: langsmith, langchain-core\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.15\n",
            "    Uninstalling langsmith-0.3.15:\n",
            "      Successfully uninstalled langsmith-0.3.15\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.45\n",
            "    Uninstalling langchain-core-0.3.45:\n",
            "      Successfully uninstalled langchain-core-0.3.45\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-groq 0.2.5 requires langchain-core<1.0.0,>=0.3.42, but you have langchain-core 0.1.23 which is incompatible.\n",
            "langchain 0.3.20 requires langchain-core<1.0.0,>=0.3.41, but you have langchain-core 0.1.23 which is incompatible.\n",
            "langchain 0.3.20 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.0.87 which is incompatible.\n",
            "langchain-huggingface 0.1.2 requires langchain-core<0.4.0,>=0.3.15, but you have langchain-core 0.1.23 which is incompatible.\n",
            "langchain-text-splitters 0.3.6 requires langchain-core<1.0.0,>=0.3.34, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.1.23 langsmith-0.0.87\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.29.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain-huggingface)\n",
            "  Using cached langchain_core-0.3.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
            "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface)\n",
            "  Using cached langsmith-0.3.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.10.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Using cached langchain_core-0.3.45-py3-none-any.whl (415 kB)\n",
            "Using cached langsmith-0.3.15-py3-none-any.whl (343 kB)\n",
            "Installing collected packages: langsmith, langchain-core\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.87\n",
            "    Uninstalling langsmith-0.0.87:\n",
            "      Successfully uninstalled langsmith-0.0.87\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.1.23\n",
            "    Uninstalling langchain-core-0.1.23:\n",
            "      Successfully uninstalled langchain-core-0.1.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.0.4 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.3.45 which is incompatible.\n",
            "langchain-community 0.0.4 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.3.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.3.45 langsmith-0.3.15\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.29.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->accelerate) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->accelerate) (2025.1.31)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.41.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.49.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.23.8)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.7 in /usr/local/lib/python3.11/dist-packages (from pymupdf) (1.23.7)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"gemma2-9b-it\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other parameters as needed\n",
        ")\n",
        "\n",
        "print(\"gemma2-9b-it model integrated successfully!\")"
      ],
      "metadata": {
        "id": "-kdElPpECv7a",
        "outputId": "b2cc79d6-afcb-4bc7-b02b-775cd16f7489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gemma2-9b-it model integrated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt34O9_Fd1c_"
      },
      "source": [
        "### [Class ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/_modules/langchain/chains/conversational_retrieval/base.html#ConversationalRetrievalChain)\n",
        "\n",
        "- `retriever` : Retriever to use to fetch documents.\n",
        "\n",
        "- `combine_docs_chain` : The chain used to combine any retrieved documents.\n",
        "\n",
        "- `question_generator`: The chain used to generate a new question for the sake of retrieval. This chain will take in the current question (with variable question) and any chat history (with variable chat_history) and will produce a new standalone question to be used later on.\n",
        "\n",
        "- `return_source_documents` : Return the retrieved source documents as part of the final result.\n",
        "\n",
        "- `get_chat_history` : An optional function to get a string of the chat history. If None is provided, will use a default.\n",
        "\n",
        "- `return_generated_question` : Return the generated question as part of the final result.\n",
        "\n",
        "- `response_if_no_docs_found` : If specified, the chain will return a fixed response if no docs are found for the question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDz3ED7Kd1c_"
      },
      "source": [
        "`question_generator`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d--xD9zpd1dA"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA6oKD8Ed1dA",
        "outputId": "730f9ba3-71cc-4869-d72d-4032967c8df0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['chat_history', 'question'], input_types={}, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "CONDENSE_QUESTION_PROMPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1sHwvEH7d1dA"
      },
      "outputs": [],
      "source": [
        "question_generator = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = CONDENSE_QUESTION_PROMPT,\n",
        "    verbose = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0aubOwcd1dA",
        "outputId": "231af7ba-1967-489c-dd51-aa714e2b9cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "Human:What is your name\n",
            "AI:\n",
            "Human:What is your highest level of education\n",
            "AI:\n",
            "Follow Up Input: Tell me about yourself\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chat_history': 'Human:What is your name\\nAI:\\nHuman:What is your highest level of education\\nAI:',\n",
              " 'question': 'Tell me about yourself',\n",
              " 'text': 'Tell me about yourself. \\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "query = 'Tell me about yourself'\n",
        "chat_history = \"Human:What is your name\\nAI:\\nHuman:What is your highest level of education\\nAI:\"\n",
        "\n",
        "question_generator({'chat_history' : chat_history, \"question\" : query})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnFvfKt_d1dB"
      },
      "source": [
        "`combine_docs_chain`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf8RqfI6d1dB",
        "outputId": "f0488fb1-0662-4c09-99a7-0ba3470ff9a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-476f6286f0f4>:1: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
            "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
            "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
            "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
            "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
            "\n",
            "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
            "  doc_chain = load_qa_chain(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\\n    The current year is 2025, and all answers should reflect this year unless otherwise specified.\\n    Whether you're curious about my education, work experience, or personal interests,\\n    I’ll provide accurate and gentle responses using the information I have.\\n    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x79799b9f7910>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79799b351f90>, model_name='gemma2-9b-it', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "doc_chain = load_qa_chain(\n",
        "    llm = llm,\n",
        "    chain_type = 'stuff',\n",
        "    prompt = PROMPT,\n",
        "    verbose = True\n",
        ")\n",
        "doc_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo6VpwXOd1dB",
        "outputId": "322d0805-1792-4290-812e-cf9795ff6db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-365d8a84c375>:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  input_document = retriever.get_relevant_documents(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "June 2022 – December 2023\n",
            "Computer Programmer | EduTech Social Enterprise, Yangon\n",
            "I built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\n",
            "\n",
            "September 2020 – March 2022\n",
            "Junior Software Engineer | Bliss Stock Co., Ltd, Japan\n",
            "I maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.\n",
            "\n",
            "Mya Mjechal\n",
            "Full Stack Developer\n",
            "\n",
            "Pathum Thani, Thailand\n",
            "myamjechal.mj@gmail.com\n",
            "\n",
            "Birthday: September 16, 1999\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "January 2025 – Present\n",
            "Technical Support | intERLab (Asian Institute of Technology)\n",
            "As a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\n",
            "\n",
            "January 2024 – December 2024\n",
            "Senior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\n",
            "I developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\n",
            "    Question: How old are you?\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_documents': [Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='ADDITIONAL INFORMATION\\n\\nAge: 25 years old (as of 2025)\\n\\nHighest Level of Education: Master of Science (Expected May 2025)\\n\\nMajor: Data Science and Artificial Intelligence\\n\\nWork Experience: Over 4 years in software development, full-stack development, and technical support\\n\\nIndustries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\\n\\nCurrent Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\\n\\nCore Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.'),\n",
              "  Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='June 2022 – December 2023\\nComputer Programmer | EduTech Social Enterprise, Yangon\\nI built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\\n\\nSeptember 2020 – March 2022\\nJunior Software Engineer | Bliss Stock Co., Ltd, Japan\\nI maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.'),\n",
              "  Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='Mya Mjechal\\nFull Stack Developer\\n\\nPathum Thani, Thailand\\nmyamjechal.mj@gmail.com\\n\\nBirthday: September 16, 1999'),\n",
              "  Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='WORK EXPERIENCE\\n\\nJanuary 2025 – Present\\nTechnical Support | intERLab (Asian Institute of Technology)\\nAs a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\\n\\nJanuary 2024 – December 2024\\nSenior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\\nI developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.')],\n",
              " 'question': 'How old are you?',\n",
              " 'output_text': 'I am 25 years old.  \\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "query = \"How old are you?\"\n",
        "input_document = retriever.get_relevant_documents(query)\n",
        "\n",
        "doc_chain({'input_documents':input_document, 'question':query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po2GMMnXd1dB",
        "outputId": "01b76c13-aa27-4cad-cb6b-630da2adfe23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-18b584bb4aca>:8: LangChainDeprecationWarning: The class `ConversationalRetrievalChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~create_history_aware_retriever together with create_retrieval_chain (see example in docstring)` instead.\n",
            "  chain = ConversationalRetrievalChain(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(chat_memory=InMemoryChatMessageHistory(messages=[]), output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"I'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\\n    The current year is 2025, and all answers should reflect this year unless otherwise specified.\\n    Whether you're curious about my education, work experience, or personal interests,\\n    I’ll provide accurate and gentle responses using the information I have.\\n    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\\n    {context}\\n    Question: {question}\\n    Answer:\"), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x79799b9f7910>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79799b351f90>, model_name='gemma2-9b-it', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], input_types={}, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x79799b9f7910>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x79799b351f90>, model_name='gemma2-9b-it', temperature=1e-08, model_kwargs={}, groq_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}), return_source_documents=True, get_chat_history=<function <lambda> at 0x79799b3194e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x797802766790>, search_kwargs={}))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "memory = ConversationBufferWindowMemory(\n",
        "    k=3,\n",
        "    memory_key = \"chat_history\",\n",
        "    return_messages = True,\n",
        "    output_key = 'answer'\n",
        ")\n",
        "\n",
        "chain = ConversationalRetrievalChain(\n",
        "    retriever=retriever,\n",
        "    question_generator=question_generator,\n",
        "    combine_docs_chain=doc_chain,\n",
        "    return_source_documents=True,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    get_chat_history=lambda h : h\n",
        ")\n",
        "chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg5Xtq1Td1dC"
      },
      "source": [
        "## 5. Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHmLW1v_d1dC",
        "outputId": "765fabfd-c607-4837-ee53-8afa42c8b918"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    PERSONAL INFORMATION\n",
            "Address: Pathum Thani, Thailand\n",
            "Nationality: Burmese\n",
            "Driving License: No\n",
            "Hobbies: Reading, watching movies and series, coding, singing and listening to music\n",
            "\n",
            "LANGUAGES\n",
            "Burmese - Native\n",
            "English - Fluent\n",
            "Japanese - N3\n",
            "Thai - Beginner\n",
            "\n",
            "Mya Mjechal\n",
            "Full Stack Developer\n",
            "\n",
            "Pathum Thani, Thailand\n",
            "myamjechal.mj@gmail.com\n",
            "\n",
            "Birthday: September 16, 1999\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "January 2025 – Present\n",
            "Technical Support | intERLab (Asian Institute of Technology)\n",
            "As a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\n",
            "\n",
            "January 2024 – December 2024\n",
            "Senior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\n",
            "I developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "    Question: Who are you by the way?\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Who are you by the way?',\n",
              " 'chat_history': [],\n",
              " 'answer': \"Hello! I'm MJBot, your friendly NLP chatbot. I'm here to tell you all about Mya Mjechal based on the information I have.  Think of me as her digital assistant, ready to answer your questions about her background, work, and interests.  \\n\\nWhat would you like to know about Mya? 😊 \\n\\n\",\n",
              " 'source_documents': [Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='PERSONAL INFORMATION\\nAddress: Pathum Thani, Thailand\\nNationality: Burmese\\nDriving License: No\\nHobbies: Reading, watching movies and series, coding, singing and listening to music\\n\\nLANGUAGES\\nBurmese - Native\\nEnglish - Fluent\\nJapanese - N3\\nThai - Beginner'),\n",
              "  Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='Mya Mjechal\\nFull Stack Developer\\n\\nPathum Thani, Thailand\\nmyamjechal.mj@gmail.com\\n\\nBirthday: September 16, 1999'),\n",
              "  Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='WORK EXPERIENCE\\n\\nJanuary 2025 – Present\\nTechnical Support | intERLab (Asian Institute of Technology)\\nAs a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\\n\\nJanuary 2024 – December 2024\\nSenior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\\nI developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.'),\n",
              "  Document(metadata={'source': 'data/MyaMjechal-CV.txt'}, page_content='ADDITIONAL INFORMATION\\n\\nAge: 25 years old (as of 2025)\\n\\nHighest Level of Education: Master of Science (Expected May 2025)\\n\\nMajor: Data Science and Artificial Intelligence\\n\\nWork Experience: Over 4 years in software development, full-stack development, and technical support\\n\\nIndustries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\\n\\nCurrent Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\\n\\nCore Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "prompt_question = \"Who are you by the way?\"\n",
        "answer = chain({\"question\":prompt_question})\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer['answer']"
      ],
      "metadata": {
        "id": "ujt85KJ2SyWo",
        "outputId": "1a958861-80d5-4913-fe7f-276c11b58c42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello! I'm MJBot, your friendly NLP chatbot. I'm here to tell you all about Mya Mjechal based on the information I have.  Think of me as her digital assistant, ready to answer your questions about her background, work, and interests.  \\n\\nWhat would you like to know about Mya? 😊 \\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SUOZu-wGd1dD"
      },
      "outputs": [],
      "source": [
        "queries = [\"How old are you?\",\n",
        "           \"What is your highest level of education?\",\n",
        "           \"What major or field of study did you pursue during your education?\",\n",
        "           \"How many years of work experience do you have?\",\n",
        "           \"What type of work or industry have you been involved in?\",\n",
        "           \"Can you describe your current role or job responsibilities?\",\n",
        "           \"What are your core beliefs regarding the role of technology in shaping society?\",\n",
        "           \"How do you think cultural values should influence technological advancements?\",\n",
        "           \"As a master’s student, what is the most challenging aspect of your studies so far?\",\n",
        "           \"What specific research interests or academic goals do you hope to achieve during your time as a master's student?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5mmMzATd1dD",
        "outputId": "ec6756dd-073d-4236-f917-59fa899c8a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Who are you by the way?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm MJBot, your friendly NLP chatbot. I'm here to tell you all about Mya Mjechal based on the information I have.  Think of me as her digital assistant, ready to answer your questions about her background, work, and interests.  \\n\\nWhat would you like to know about Mya? 😊 \\n\\n\", additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: How old are you?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "June 2022 – December 2023\n",
            "Computer Programmer | EduTech Social Enterprise, Yangon\n",
            "I built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\n",
            "\n",
            "September 2020 – March 2022\n",
            "Junior Software Engineer | Bliss Stock Co., Ltd, Japan\n",
            "I maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.\n",
            "\n",
            "Mya Mjechal\n",
            "Full Stack Developer\n",
            "\n",
            "Pathum Thani, Thailand\n",
            "myamjechal.mj@gmail.com\n",
            "\n",
            "Birthday: September 16, 1999\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "January 2025 – Present\n",
            "Technical Support | intERLab (Asian Institute of Technology)\n",
            "As a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\n",
            "\n",
            "January 2024 – December 2024\n",
            "Senior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\n",
            "I developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\n",
            "    Question: How old are you? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Who are you by the way?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm MJBot, your friendly NLP chatbot. I'm here to tell you all about Mya Mjechal based on the information I have.  Think of me as her digital assistant, ready to answer your questions about her background, work, and interests.  \\n\\nWhat would you like to know about Mya? 😊 \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How old are you?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am 25 years old.  \\n', additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: What is your highest level of education?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "LANGUAGES\n",
            "Burmese - Native\n",
            "English - Fluent\n",
            "Japanese - N3\n",
            "Thai - Beginner\n",
            "\n",
            "SKILLS\n",
            "Self-motivation, Decision Making, Fast Learner, Problem Solving, Critical Thinking, Teamwork, Customer Service, Adaptability, Computer Skills, Leadership Skills, Communication Skills, Effective Time Management, Attention to Detail, Ability to Work in a Team, Ability to Work Under Pressure, Microsoft Office, Python, Odoo, JavaScript, HTML & CSS, Bootstrap, Java, PHP, Wordpress, Git, Linux, Docker, Node.js, SQL, MySQL, PostgreSQL, Figma & Adobe XD\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including\n",
            "\n",
            "Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "    Question: What is your highest level of education? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Who are you by the way?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! I'm MJBot, your friendly NLP chatbot. I'm here to tell you all about Mya Mjechal based on the information I have.  Think of me as her digital assistant, ready to answer your questions about her background, work, and interests.  \\n\\nWhat would you like to know about Mya? 😊 \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How old are you?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am 25 years old.  \\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your highest level of education?', additional_kwargs={}, response_metadata={}), AIMessage(content='My highest level of education is a Master of Science, which I am expecting to complete in May 2025.  \\n\\n', additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: What major or field of study did you pursue during your education?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "\n",
            "I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including\n",
            "\n",
            "LANGUAGES\n",
            "Burmese - Native\n",
            "English - Fluent\n",
            "Japanese - N3\n",
            "Thai - Beginner\n",
            "\n",
            "SKILLS\n",
            "Self-motivation, Decision Making, Fast Learner, Problem Solving, Critical Thinking, Teamwork, Customer Service, Adaptability, Computer Skills, Leadership Skills, Communication Skills, Effective Time Management, Attention to Detail, Ability to Work in a Team, Ability to Work Under Pressure, Microsoft Office, Python, Odoo, JavaScript, HTML & CSS, Bootstrap, Java, PHP, Wordpress, Git, Linux, Docker, Node.js, SQL, MySQL, PostgreSQL, Figma & Adobe XD\n",
            "\n",
            "WORK EXPERIENCE\n",
            "    Question: What major or field of study did you pursue during your education? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='How old are you?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am 25 years old.  \\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your highest level of education?', additional_kwargs={}, response_metadata={}), AIMessage(content='My highest level of education is a Master of Science, which I am expecting to complete in May 2025.  \\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What major or field of study did you pursue during your education?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"My major is Data Science and Artificial Intelligence. I'm expecting to graduate with my Master of Science in May 2025.  \\n\", additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: How many years of work experience do you have?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "January 2025 – Present\n",
            "Technical Support | intERLab (Asian Institute of Technology)\n",
            "As a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\n",
            "\n",
            "January 2024 – December 2024\n",
            "Senior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\n",
            "I developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\n",
            "\n",
            "I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including\n",
            "\n",
            "June 2022 – December 2023\n",
            "Computer Programmer | EduTech Social Enterprise, Yangon\n",
            "I built a chatbot and LMS dashboard, provided IT support, and shared knowledge with peers.\n",
            "\n",
            "September 2020 – March 2022\n",
            "Junior Software Engineer | Bliss Stock Co., Ltd, Japan\n",
            "I maintained a WordPress job application site, developed an educational website, and researched Google Speech-to-Text API integration.\n",
            "    Question: How many years of work experience do you have? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='What is your highest level of education?', additional_kwargs={}, response_metadata={}), AIMessage(content='My highest level of education is a Master of Science, which I am expecting to complete in May 2025.  \\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What major or field of study did you pursue during your education?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"My major is Data Science and Artificial Intelligence. I'm expecting to graduate with my Master of Science in May 2025.  \\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How many years of work experience do you have?', additional_kwargs={}, response_metadata={}), AIMessage(content='I have over 4 years of work experience.  \\n', additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: What type of work or industry have you been involved in?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "\n",
            "I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "January 2025 – Present\n",
            "Technical Support | intERLab (Asian Institute of Technology)\n",
            "As a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\n",
            "\n",
            "January 2024 – December 2024\n",
            "Senior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\n",
            "I developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\n",
            "    Question: What type of work or industry have you been involved in? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='What major or field of study did you pursue during your education?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"My major is Data Science and Artificial Intelligence. I'm expecting to graduate with my Master of Science in May 2025.  \\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How many years of work experience do you have?', additional_kwargs={}, response_metadata={}), AIMessage(content='I have over 4 years of work experience.  \\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What type of work or industry have you been involved in?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I've been involved in a variety of work and industries!  \\n\\nMy experience spans:\\n\\n* **EduTech:** Developing chatbots and dashboards for educational purposes.\\n* **IT Services:** Providing technical support and troubleshooting.\\n* **Software Development:**  Building Odoo apps for local businesses and working on full-stack development projects.\\n* **Cloud Computing:**  Gaining experience with platforms like OpenStack and working on cloud-based solutions.\\n* **AI/ML:**  Applying my knowledge of data science and artificial intelligence in projects and contests.\\n* **WordPress Development:**  Focusing on website migration, troubleshooting, and system configurations. \\n\\n\\nLet me know if you'd like to know more about a specific area! \\n\\n\", additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: Can you describe your current role or job responsibilities?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "January 2025 – Present\n",
            "Technical Support | intERLab (Asian Institute of Technology)\n",
            "As a Freelance Technical Support Student Assistant at intERLab, AIT, I work on WordPress migration, ensuring smooth website transfers and functionality. I troubleshoot technical issues, assist with system configurations, and improve website performance.\n",
            "\n",
            "January 2024 – December 2024\n",
            "Senior Associate Full Stack Developer | EduTech Social Enterprise, Yangon\n",
            "I developed a versatile chatbot and an LMS dashboard for internal and external users. I set up a staging server for testing and provided IT support, mentoring junior team members.\n",
            "\n",
            "Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "\n",
            "LANGUAGES\n",
            "Burmese - Native\n",
            "English - Fluent\n",
            "Japanese - N3\n",
            "Thai - Beginner\n",
            "\n",
            "SKILLS\n",
            "Self-motivation, Decision Making, Fast Learner, Problem Solving, Critical Thinking, Teamwork, Customer Service, Adaptability, Computer Skills, Leadership Skills, Communication Skills, Effective Time Management, Attention to Detail, Ability to Work in a Team, Ability to Work Under Pressure, Microsoft Office, Python, Odoo, JavaScript, HTML & CSS, Bootstrap, Java, PHP, Wordpress, Git, Linux, Docker, Node.js, SQL, MySQL, PostgreSQL, Figma & Adobe XD\n",
            "\n",
            "WORK EXPERIENCE\n",
            "    Question: Can you describe your current role and job responsibilities? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='How many years of work experience do you have?', additional_kwargs={}, response_metadata={}), AIMessage(content='I have over 4 years of work experience.  \\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What type of work or industry have you been involved in?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I've been involved in a variety of work and industries!  \\n\\nMy experience spans:\\n\\n* **EduTech:** Developing chatbots and dashboards for educational purposes.\\n* **IT Services:** Providing technical support and troubleshooting.\\n* **Software Development:**  Building Odoo apps for local businesses and working on full-stack development projects.\\n* **Cloud Computing:**  Gaining experience with platforms like OpenStack and working on cloud-based solutions.\\n* **AI/ML:**  Applying my knowledge of data science and artificial intelligence in projects and contests.\\n* **WordPress Development:**  Focusing on website migration, troubleshooting, and system configurations. \\n\\n\\nLet me know if you'd like to know more about a specific area! \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you describe your current role or job responsibilities?', additional_kwargs={}, response_metadata={}), AIMessage(content='As a Freelance Technical Support Student Assistant at intERLab, a part of the Asian Institute of Technology, my main focus is on WordPress migration.  \\n\\nThis means I help organizations smoothly transfer their websites to WordPress, ensuring everything works correctly after the switch. I also troubleshoot any technical issues they might encounter and assist with setting up their WordPress sites for optimal performance. \\n\\n\\n\\n', additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: What are your core beliefs regarding the role of technology in shaping society?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    Cultural Values in Technology: Cultural values should be respected and incorporated into technological advancements to ensure inclusivity and fairness.\n",
            "\n",
            "Challenges in Master’s Studies: Managing multiple deadlines, balancing coursework with part-time work, and handling computational limitations.\n",
            "\n",
            "Research Interests and Academic Goals: NLP, AI ethics, and computational efficiency in machine translation and big data analysis.\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "\n",
            "I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including\n",
            "    Question: What are your core beliefs regarding the role of technology in shaping society? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='What type of work or industry have you been involved in?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I've been involved in a variety of work and industries!  \\n\\nMy experience spans:\\n\\n* **EduTech:** Developing chatbots and dashboards for educational purposes.\\n* **IT Services:** Providing technical support and troubleshooting.\\n* **Software Development:**  Building Odoo apps for local businesses and working on full-stack development projects.\\n* **Cloud Computing:**  Gaining experience with platforms like OpenStack and working on cloud-based solutions.\\n* **AI/ML:**  Applying my knowledge of data science and artificial intelligence in projects and contests.\\n* **WordPress Development:**  Focusing on website migration, troubleshooting, and system configurations. \\n\\n\\nLet me know if you'd like to know more about a specific area! \\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Can you describe your current role or job responsibilities?', additional_kwargs={}, response_metadata={}), AIMessage(content='As a Freelance Technical Support Student Assistant at intERLab, a part of the Asian Institute of Technology, my main focus is on WordPress migration.  \\n\\nThis means I help organizations smoothly transfer their websites to WordPress, ensuring everything works correctly after the switch. I also troubleshoot any technical issues they might encounter and assist with setting up their WordPress sites for optimal performance. \\n\\n\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are your core beliefs regarding the role of technology in shaping society?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I believe technology should be a force for good in society.  \\n\\nMy core belief is that technology should enhance accessibility, education, and opportunities for everyone while being developed and used ethically and responsibly. I think it's important to consider the cultural impact of technology and make sure it's inclusive and fair for all. \\n\", additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: How do you think cultural values should influence technological advancements?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    Cultural Values in Technology: Cultural values should be respected and incorporated into technological advancements to ensure inclusivity and fairness.\n",
            "\n",
            "Challenges in Master’s Studies: Managing multiple deadlines, balancing coursework with part-time work, and handling computational limitations.\n",
            "\n",
            "Research Interests and Academic Goals: NLP, AI ethics, and computational efficiency in machine translation and big data analysis.\n",
            "\n",
            "Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "EDUCATION\n",
            "Asian Institute of Technology (AIT), Pathum Thani\n",
            "Master of Science in Data Science and Artificial Intelligence (Expected May 2025)\n",
            "University of Information Technology, Yangon\n",
            "B.C.Sc (High Performance Computing), Graduated 2020\n",
            "KMD Institute, Yangon\n",
            "NCC Level 4 Diploma in Computing, Graduated 2018\n",
            "\n",
            "INTERNSHIPS\n",
            "\n",
            "June 2020 – August 2020\n",
            "Junior Software Engineer | Bliss Stock Co., Ltd.\n",
            "Developed an e-commerce mobile app with Flutter, Firebase, and Algolia.\n",
            "\n",
            "ACTIVITIES\n",
            "\n",
            "Committee Member (Gender and Culture Committee of AIT Student Union), January 2025 – Present\n",
            "\n",
            "Volunteer Project Coordinator (Career Readiness Program), Yangon, January 2023 – July 2023\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "    Question: How do you think cultural values should influence technological advancements? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='Can you describe your current role or job responsibilities?', additional_kwargs={}, response_metadata={}), AIMessage(content='As a Freelance Technical Support Student Assistant at intERLab, a part of the Asian Institute of Technology, my main focus is on WordPress migration.  \\n\\nThis means I help organizations smoothly transfer their websites to WordPress, ensuring everything works correctly after the switch. I also troubleshoot any technical issues they might encounter and assist with setting up their WordPress sites for optimal performance. \\n\\n\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='What are your core beliefs regarding the role of technology in shaping society?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I believe technology should be a force for good in society.  \\n\\nMy core belief is that technology should enhance accessibility, education, and opportunities for everyone while being developed and used ethically and responsibly. I think it's important to consider the cultural impact of technology and make sure it's inclusive and fair for all. \\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How do you think cultural values should influence technological advancements?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question! I believe cultural values are incredibly important to consider when developing new technologies.  \\n\\nWe need to make sure technology is inclusive and fair for everyone, which means taking into account the diverse beliefs, customs, and perspectives of different cultures.  \\n\\nFor example, language is a huge part of culture, and technology should be designed to be accessible in as many languages as possible.  \\n\\nSimilarly,  cultural norms around privacy and data sharing can vary widely, so technology should be developed with these differences in mind. \\n\\nBy respecting and incorporating cultural values, we can create technology that truly benefits all of humanity. \\n\", additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: As a master’s student, what is the most challenging aspect of your studies so far?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    Cultural Values in Technology: Cultural values should be respected and incorporated into technological advancements to ensure inclusivity and fairness.\n",
            "\n",
            "Challenges in Master’s Studies: Managing multiple deadlines, balancing coursework with part-time work, and handling computational limitations.\n",
            "\n",
            "Research Interests and Academic Goals: NLP, AI ethics, and computational efficiency in machine translation and big data analysis.\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "\n",
            "I am a skilled developer with expertise in developing chatbots and dashboards, with additional skills in Natural Language Understanding (NLU) and Natural Language Processing (NLP) at EduTech Social Enterprise. I have experience as a freelancer, developing Odoo apps for local businesses, and a background in Software Development Management at Bliss Stock Co., Ltd. I am knowledgeable in Cluster Computing, Cloud Computing, Virtualization, Big Data Analysis, Networking, Web Programming, Blockchain, and IoT. I participated in the Huawei Cloud & AI contest, gaining experience in Data Mining, Image Processing, Data Prediction, and Cloud Usage. I implemented technologies in class projects, including\n",
            "    Question: As a master's student, what is the most challenging aspect of your studies so far? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
            "\n",
            "Chat History:\n",
            "[HumanMessage(content='What are your core beliefs regarding the role of technology in shaping society?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I believe technology should be a force for good in society.  \\n\\nMy core belief is that technology should enhance accessibility, education, and opportunities for everyone while being developed and used ethically and responsibly. I think it's important to consider the cultural impact of technology and make sure it's inclusive and fair for all. \\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='How do you think cultural values should influence technological advancements?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question! I believe cultural values are incredibly important to consider when developing new technologies.  \\n\\nWe need to make sure technology is inclusive and fair for everyone, which means taking into account the diverse beliefs, customs, and perspectives of different cultures.  \\n\\nFor example, language is a huge part of culture, and technology should be designed to be accessible in as many languages as possible.  \\n\\nSimilarly,  cultural norms around privacy and data sharing can vary widely, so technology should be developed with these differences in mind. \\n\\nBy respecting and incorporating cultural values, we can create technology that truly benefits all of humanity. \\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='As a master’s student, what is the most challenging aspect of your studies so far?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's a great question!  As a master's student, I'd say the most challenging aspect is definitely managing all the deadlines.  Balancing coursework with my part-time work can be tough, and sometimes it feels like there just aren't enough hours in the day!  \\n\\nI'm learning to prioritize and be really efficient with my time, though.  \\n\\n\", additional_kwargs={}, response_metadata={})]\n",
            "Follow Up Input: What specific research interests or academic goals do you hope to achieve during your time as a master's student?\n",
            "Standalone question:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI'm your friendly NLP chatbot named MJBot, here to to answer questions about Mya Mjechal myself based on my knowledge from my CV and personal data.\n",
            "    The current year is 2025, and all answers should reflect this year unless otherwise specified.\n",
            "    Whether you're curious about my education, work experience, or personal interests,\n",
            "    I’ll provide accurate and gentle responses using the information I have.\n",
            "    If I don't know something, I'll let you know kindly. Just let me know what you're wondering about, and I'll do my best to guide you through it!\n",
            "    Cultural Values in Technology: Cultural values should be respected and incorporated into technological advancements to ensure inclusivity and fairness.\n",
            "\n",
            "Challenges in Master’s Studies: Managing multiple deadlines, balancing coursework with part-time work, and handling computational limitations.\n",
            "\n",
            "Research Interests and Academic Goals: NLP, AI ethics, and computational efficiency in machine translation and big data analysis.\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "Age: 25 years old (as of 2025)\n",
            "\n",
            "Highest Level of Education: Master of Science (Expected May 2025)\n",
            "\n",
            "Major: Data Science and Artificial Intelligence\n",
            "\n",
            "Work Experience: Over 4 years in software development, full-stack development, and technical support\n",
            "\n",
            "Industries: EduTech, IT Services, Software Development, Cloud Computing, AI/ML, and WordPress development\n",
            "\n",
            "Current Role: Freelance Technical Support at intERLab, focusing on WordPress migration, troubleshooting, and system configurations\n",
            "\n",
            "Core Beliefs on Technology: Technology should enhance accessibility, education, and opportunities while being ethically and culturally responsible.\n",
            "\n",
            "Data Prediction, and Cloud Usage. I implemented technologies in class projects, including OpenStack, Hyper-V Failover Clustering, Student Online Result System, and a Restaurant Guide Website. I have strong leadership and relationship-building skills, gained through interaction with ASEAN leaders and participants.\n",
            "\n",
            "EDUCATION\n",
            "Asian Institute of Technology (AIT), Pathum Thani\n",
            "Master of Science in Data Science and Artificial Intelligence (Expected May 2025)\n",
            "University of Information Technology, Yangon\n",
            "B.C.Sc (High Performance Computing), Graduated 2020\n",
            "KMD Institute, Yangon\n",
            "NCC Level 4 Diploma in Computing, Graduated 2018\n",
            "\n",
            "INTERNSHIPS\n",
            "\n",
            "June 2020 – August 2020\n",
            "Junior Software Engineer | Bliss Stock Co., Ltd.\n",
            "Developed an e-commerce mobile app with Flutter, Firebase, and Algolia.\n",
            "\n",
            "ACTIVITIES\n",
            "\n",
            "Committee Member (Gender and Culture Committee of AIT Student Union), January 2025 – Present\n",
            "\n",
            "Volunteer Project Coordinator (Career Readiness Program), Yangon, January 2023 – July 2023\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "    Question: What specific research interests or academic goals do you hope to achieve during your time as a master's student? \n",
            "\n",
            "    Answer:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Saved to json file\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "qa_pairs = [\n",
        "    {\"question\": prompt_question, \"answer\": chain({\"question\": prompt_question})[\"answer\"]}\n",
        "    for prompt_question in queries\n",
        "]\n",
        "\n",
        "# Save to a JSON file\n",
        "with open(\"qa_pairs.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(qa_pairs, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Saved to json file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qysVltcd1dD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLiWgCa7d1dD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5a48b89309c45a2b679df9dc35a3b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_a3c28c0e04b1431f9916a8aaeb939d66"
          }
        },
        "28f84346a335472ebd9ac8962d693f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_315f7887060a472bbcb8844057f8ba14",
            "placeholder": "​",
            "style": "IPY_MODEL_ce66647915314fe0a4434ce61d164896",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "05874bcd86ec4c288aecfdb13c26a58e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3ab966cda0d9465cbbe102a1dd21c8f8",
            "placeholder": "​",
            "style": "IPY_MODEL_f72a415b238e4b409d7536e1e48f7bd1",
            "value": ""
          }
        },
        "1a1a1cfd2b0c41cc96b95ebf924e3414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cd29e61801154e5bb447b9ead88817fd",
            "style": "IPY_MODEL_8d819776ab4e4922b671d072d6006e17",
            "value": true
          }
        },
        "8372c4a099f34b1086a58b4af8612fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_528706e42460467dada46e8b52b7bd71",
            "style": "IPY_MODEL_cb2833e488b74d3b897b75d82c955371",
            "tooltip": ""
          }
        },
        "e152689840e34ceea7b7480983689230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c44442e3ce4ec4a065b6a763bab89e",
            "placeholder": "​",
            "style": "IPY_MODEL_a00616df3948488d9e78dd414f1fb13f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a3c28c0e04b1431f9916a8aaeb939d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "315f7887060a472bbcb8844057f8ba14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce66647915314fe0a4434ce61d164896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ab966cda0d9465cbbe102a1dd21c8f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72a415b238e4b409d7536e1e48f7bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd29e61801154e5bb447b9ead88817fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d819776ab4e4922b671d072d6006e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "528706e42460467dada46e8b52b7bd71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2833e488b74d3b897b75d82c955371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c2c44442e3ce4ec4a065b6a763bab89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a00616df3948488d9e78dd414f1fb13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e6d0fc5cf5c4961ad8a6def0c7ef009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ebc13907e94811a86c0a0315c2b095",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc4161368cf476db2d6518df0867b43",
            "value": "Connecting..."
          }
        },
        "97ebc13907e94811a86c0a0315c2b095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc4161368cf476db2d6518df0867b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}